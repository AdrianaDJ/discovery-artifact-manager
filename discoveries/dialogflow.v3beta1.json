{
  "fullyEncodeReservedExpansion": true,
  "servicePath": "",
  "protocol": "rest",
  "kind": "discovery#restDescription",
  "version_module": true,
  "baseUrl": "https://dialogflow.googleapis.com/",
  "id": "dialogflow:v3beta1",
  "canonicalName": "Dialogflow",
  "batchPath": "batch",
  "ownerName": "Google",
  "description": "Builds conversational interfaces (for example, chatbots, and voice-powered apps and devices).",
  "schemas": {
    "GoogleCloudDialogflowV2beta1IntentMessageRbmCardContentRbmMedia": {
      "properties": {
        "fileUri": {
          "type": "string",
          "description": "Required. Publicly reachable URI of the file. The RBM platform determines the MIME type of the file from the content-type field in the HTTP headers when the platform fetches the file. The content-type field must be present and accurate in the HTTP response from the URL."
        },
        "height": {
          "enum": [
            "HEIGHT_UNSPECIFIED",
            "SHORT",
            "MEDIUM",
            "TALL"
          ],
          "enumDescriptions": [
            "Not specified.",
            "112 DP.",
            "168 DP.",
            "264 DP. Not available for rich card carousels when the card width is set to small."
          ],
          "type": "string",
          "description": "Required for cards with vertical orientation. The height of the media within a rich card with a vertical layout. For a standalone card with horizontal layout, height is not customizable, and this field is ignored."
        },
        "thumbnailUri": {
          "type": "string",
          "description": "Optional. Publicly reachable URI of the thumbnail.If you don't provide a thumbnail URI, the RBM platform displays a blank placeholder thumbnail until the user's device downloads the file. Depending on the user's setting, the file may not download automatically and may require the user to tap a download button."
        }
      },
      "id": "GoogleCloudDialogflowV2beta1IntentMessageRbmCardContentRbmMedia",
      "description": "Rich Business Messaging (RBM) Media displayed in Cards The following media-types are currently supported: Image Types * image/jpeg * image/jpg' * image/gif * image/png Video Types * video/h263 * video/m4v * video/mp4 * video/mpeg * video/mpeg4 * video/webm",
      "type": "object"
    },
    "GoogleCloudDialogflowV2beta1IntentMessageRbmCarouselCard": {
      "id": "GoogleCloudDialogflowV2beta1IntentMessageRbmCarouselCard",
      "properties": {
        "cardContents": {
          "type": "array",
          "description": "Required. The cards in the carousel. A carousel must have at least 2 cards and at most 10.",
          "items": {
            "$ref": "GoogleCloudDialogflowV2beta1IntentMessageRbmCardContent"
          }
        },
        "cardWidth": {
          "enum": [
            "CARD_WIDTH_UNSPECIFIED",
            "SMALL",
            "MEDIUM"
          ],
          "enumDescriptions": [
            "Not specified.",
            "120 DP. Note that tall media cannot be used.",
            "232 DP."
          ],
          "type": "string",
          "description": "Required. The width of the cards in the carousel."
        }
      },
      "description": "Carousel Rich Business Messaging (RBM) rich card. Rich cards allow you to respond to users with more vivid content, e.g. with media and suggestions. If you want to show a single card with more control over the layout, please use RbmStandaloneCard instead.",
      "type": "object"
    },
    "GoogleCloudDialogflowV2beta1AutoApproveSmartMessagingEntriesResponse": {
      "id": "GoogleCloudDialogflowV2beta1AutoApproveSmartMessagingEntriesResponse",
      "type": "object",
      "properties": {
        "enabledCount": {
          "format": "int32",
          "description": "Number of smart messaging entries enabled.",
          "type": "integer"
        },
        "disabledCount": {
          "format": "int32",
          "type": "integer",
          "description": "Number of smart messaging entries disabled."
        },
        "unreviewedCount": {
          "format": "int32",
          "description": "Number of smart messaging entries unreviewed.",
          "type": "integer"
        }
      },
      "description": "Response message for [Documents.AutoApproveSmartMessagingEntries]."
    },
    "GoogleCloudDialogflowV2beta1IntentMessageTelephonyTransferCall": {
      "id": "GoogleCloudDialogflowV2beta1IntentMessageTelephonyTransferCall",
      "properties": {
        "phoneNumber": {
          "description": "Required. The phone number to transfer the call to in [E.164 format](https://en.wikipedia.org/wiki/E.164). We currently only allow transferring to US numbers (+1xxxyyyzzzz).",
          "type": "string"
        }
      },
      "type": "object",
      "description": "Transfers the call in Telephony Gateway."
    },
    "GoogleProtobufEmpty": {
      "description": "A generic empty message that you can re-use to avoid defining duplicated empty messages in your APIs. A typical example is to use it as the request or the response type of an API method. For instance: service Foo { rpc Bar(google.protobuf.Empty) returns (google.protobuf.Empty); } The JSON representation for `Empty` is empty JSON object `{}`.",
      "id": "GoogleProtobufEmpty",
      "properties": {},
      "type": "object"
    },
    "GoogleCloudDialogflowV2SentimentAnalysisResult": {
      "properties": {
        "queryTextSentiment": {
          "$ref": "GoogleCloudDialogflowV2Sentiment",
          "description": "The sentiment analysis result for `query_text`."
        }
      },
      "id": "GoogleCloudDialogflowV2SentimentAnalysisResult",
      "type": "object",
      "description": "The result of sentiment analysis. Sentiment analysis inspects user input and identifies the prevailing subjective opinion, especially to determine a user's attitude as positive, negative, or neutral. For Participants.AnalyzeContent, it needs to be configured in DetectIntentRequest.query_params. For Participants.StreamingAnalyzeContent, it needs to be configured in StreamingDetectIntentRequest.query_params. And for Participants.AnalyzeContent and Participants.StreamingAnalyzeContent, it needs to be configured in ConversationProfile.human_agent_assistant_config"
    },
    "GoogleCloudDialogflowV2WebhookRequest": {
      "type": "object",
      "id": "GoogleCloudDialogflowV2WebhookRequest",
      "properties": {
        "originalDetectIntentRequest": {
          "description": "Optional. The contents of the original request that was passed to `[Streaming]DetectIntent` call.",
          "$ref": "GoogleCloudDialogflowV2OriginalDetectIntentRequest"
        },
        "queryResult": {
          "description": "The result of the conversational query or event processing. Contains the same value as `[Streaming]DetectIntentResponse.query_result`.",
          "$ref": "GoogleCloudDialogflowV2QueryResult"
        },
        "session": {
          "description": "The unique identifier of detectIntent request session. Can be used to identify end-user inside webhook implementation. Format: `projects//agent/sessions/`, or `projects//agent/environments//users//sessions/`.",
          "type": "string"
        },
        "responseId": {
          "type": "string",
          "description": "The unique identifier of the response. Contains the same value as `[Streaming]DetectIntentResponse.response_id`."
        }
      },
      "description": "The request message for a webhook call."
    },
    "GoogleCloudDialogflowV2beta1IntentMessageSuggestion": {
      "properties": {
        "title": {
          "description": "Required. The text shown the in the suggestion chip.",
          "type": "string"
        }
      },
      "type": "object",
      "description": "The suggestion chip message that the user can tap to quickly post a reply to the conversation.",
      "id": "GoogleCloudDialogflowV2beta1IntentMessageSuggestion"
    },
    "GoogleCloudDialogflowV2beta1IntentMessageBasicCardButton": {
      "type": "object",
      "id": "GoogleCloudDialogflowV2beta1IntentMessageBasicCardButton",
      "description": "The button object that appears at the bottom of a card.",
      "properties": {
        "openUriAction": {
          "description": "Required. Action to take when a user taps on the button.",
          "$ref": "GoogleCloudDialogflowV2beta1IntentMessageBasicCardButtonOpenUriAction"
        },
        "title": {
          "description": "Required. The title of the button.",
          "type": "string"
        }
      }
    },
    "GoogleCloudDialogflowV2beta1LabelConversationResponse": {
      "type": "object",
      "description": "The response for ConversationDatasets.LabelConversation.",
      "id": "GoogleCloudDialogflowV2beta1LabelConversationResponse",
      "properties": {
        "annotatedConversationDataset": {
          "$ref": "GoogleCloudDialogflowV2beta1AnnotatedConversationDataset",
          "description": "New annotated conversation dataset created by the labeling task."
        }
      }
    },
    "GoogleCloudDialogflowV2beta1ExportAgentResponse": {
      "properties": {
        "agentUri": {
          "type": "string",
          "description": "The URI to a file containing the exported agent. This field is populated only if `agent_uri` is specified in `ExportAgentRequest`."
        },
        "agentContent": {
          "format": "byte",
          "description": "Zip compressed raw byte content for agent.",
          "type": "string"
        }
      },
      "id": "GoogleCloudDialogflowV2beta1ExportAgentResponse",
      "type": "object",
      "description": "The response message for Agents.ExportAgent."
    },
    "GoogleLongrunningListOperationsResponse": {
      "description": "The response message for Operations.ListOperations.",
      "type": "object",
      "properties": {
        "nextPageToken": {
          "type": "string",
          "description": "The standard List next-page token."
        },
        "operations": {
          "description": "A list of operations that matches the specified filter in the request.",
          "items": {
            "$ref": "GoogleLongrunningOperation"
          },
          "type": "array"
        }
      },
      "id": "GoogleLongrunningListOperationsResponse"
    },
    "GoogleCloudDialogflowV2beta1IntentMessageColumnProperties": {
      "description": "Column properties for TableCard.",
      "type": "object",
      "id": "GoogleCloudDialogflowV2beta1IntentMessageColumnProperties",
      "properties": {
        "horizontalAlignment": {
          "enum": [
            "HORIZONTAL_ALIGNMENT_UNSPECIFIED",
            "LEADING",
            "CENTER",
            "TRAILING"
          ],
          "enumDescriptions": [
            "Text is aligned to the leading edge of the column.",
            "Text is aligned to the leading edge of the column.",
            "Text is centered in the column.",
            "Text is aligned to the trailing edge of the column."
          ],
          "description": "Optional. Defines text alignment for all cells in this column.",
          "type": "string"
        },
        "header": {
          "type": "string",
          "description": "Required. Column heading."
        }
      }
    },
    "GoogleCloudDialogflowV2beta1IntentMessageBasicCard": {
      "description": "The basic card message. Useful for displaying information.",
      "properties": {
        "subtitle": {
          "type": "string",
          "description": "Optional. The subtitle of the card."
        },
        "formattedText": {
          "type": "string",
          "description": "Required, unless image is present. The body text of the card."
        },
        "buttons": {
          "description": "Optional. The collection of card buttons.",
          "items": {
            "$ref": "GoogleCloudDialogflowV2beta1IntentMessageBasicCardButton"
          },
          "type": "array"
        },
        "title": {
          "type": "string",
          "description": "Optional. The title of the card."
        },
        "image": {
          "description": "Optional. The image for the card.",
          "$ref": "GoogleCloudDialogflowV2beta1IntentMessageImage"
        }
      },
      "type": "object",
      "id": "GoogleCloudDialogflowV2beta1IntentMessageBasicCard"
    },
    "GoogleCloudDialogflowV2beta1IntentMessageRbmSuggestedActionRbmSuggestedActionShareLocation": {
      "id": "GoogleCloudDialogflowV2beta1IntentMessageRbmSuggestedActionRbmSuggestedActionShareLocation",
      "properties": {},
      "description": "Opens the device's location chooser so the user can pick a location to send back to the agent.",
      "type": "object"
    },
    "GoogleCloudDialogflowV2IntentMessageCardButton": {
      "description": "Contains information about a button.",
      "properties": {
        "text": {
          "type": "string",
          "description": "Optional. The text to show on the button."
        },
        "postback": {
          "description": "Optional. The text to send back to the Dialogflow API or a URI to open.",
          "type": "string"
        }
      },
      "id": "GoogleCloudDialogflowV2IntentMessageCardButton",
      "type": "object"
    },
    "GoogleCloudDialogflowV2beta1Sentiment": {
      "id": "GoogleCloudDialogflowV2beta1Sentiment",
      "description": "The sentiment, such as positive/negative feeling or association, for a unit of analysis, such as the query text.",
      "properties": {
        "magnitude": {
          "format": "float",
          "description": "A non-negative number in the [0, +inf) range, which represents the absolute magnitude of sentiment, regardless of score (positive or negative).",
          "type": "number"
        },
        "score": {
          "type": "number",
          "description": "Sentiment score between -1.0 (negative sentiment) and 1.0 (positive sentiment).",
          "format": "float"
        }
      },
      "type": "object"
    },
    "GoogleCloudDialogflowV2IntentTrainingPhrase": {
      "properties": {
        "name": {
          "type": "string",
          "description": "Output only. The unique identifier of this training phrase."
        },
        "type": {
          "type": "string",
          "enumDescriptions": [
            "Not specified. This value should never be used.",
            "Examples do not contain @-prefixed entity type names, but example parts can be annotated with entity types.",
            "Templates are not annotated with entity types, but they can contain @-prefixed entity type names as substrings. Template mode has been deprecated. Example mode is the only supported way to create new training phrases. If you have existing training phrases that you've created in template mode, those will continue to work."
          ],
          "description": "Required. The type of the training phrase.",
          "enum": [
            "TYPE_UNSPECIFIED",
            "EXAMPLE",
            "TEMPLATE"
          ]
        },
        "timesAddedCount": {
          "format": "int32",
          "type": "integer",
          "description": "Optional. Indicates how many times this example was added to the intent. Each time a developer adds an existing sample by editing an intent or training, this counter is increased."
        },
        "parts": {
          "description": "Required. The ordered list of training phrase parts. The parts are concatenated in order to form the training phrase. Note: The API does not automatically annotate training phrases like the Dialogflow Console does. Note: Do not forget to include whitespace at part boundaries, so the training phrase is well formatted when the parts are concatenated. If the training phrase does not need to be annotated with parameters, you just need a single part with only the Part.text field set. If you want to annotate the training phrase, you must create multiple parts, where the fields of each part are populated in one of two ways: - `Part.text` is set to a part of the phrase that has no parameters. - `Part.text` is set to a part of the phrase that you want to annotate, and the `entity_type`, `alias`, and `user_defined` fields are all set.",
          "type": "array",
          "items": {
            "$ref": "GoogleCloudDialogflowV2IntentTrainingPhrasePart"
          }
        }
      },
      "id": "GoogleCloudDialogflowV2IntentTrainingPhrase",
      "type": "object",
      "description": "Represents an example that the agent is trained on."
    },
    "GoogleCloudDialogflowV3alpha1CreateVersionOperationMetadata": {
      "type": "object",
      "description": "Metadata associated with the long running operation for Versions.CreateVersion.",
      "id": "GoogleCloudDialogflowV3alpha1CreateVersionOperationMetadata",
      "properties": {
        "version": {
          "type": "string",
          "description": "Name of the created version. Format: `projects//locations//agents//flows//versions/`."
        }
      }
    },
    "GoogleCloudDialogflowV2beta1IntentMessageRbmSuggestedActionRbmSuggestedActionOpenUri": {
      "type": "object",
      "id": "GoogleCloudDialogflowV2beta1IntentMessageRbmSuggestedActionRbmSuggestedActionOpenUri",
      "properties": {
        "uri": {
          "description": "Required. The uri to open on the user device",
          "type": "string"
        }
      },
      "description": "Opens the user's default web browser app to the specified uri If the user has an app installed that is registered as the default handler for the URL, then this app will be opened instead, and its icon will be used in the suggested action UI."
    },
    "GoogleCloudDialogflowV2beta1IntentMessageTelephonyPlayAudio": {
      "id": "GoogleCloudDialogflowV2beta1IntentMessageTelephonyPlayAudio",
      "type": "object",
      "description": "Plays audio from a file in Telephony Gateway.",
      "properties": {
        "audioUri": {
          "description": "Required. URI to a Google Cloud Storage object containing the audio to play, e.g., \"gs://bucket/object\". The object must contain a single channel (mono) of linear PCM audio (2 bytes / sample) at 8kHz. This object must be readable by the `service-@gcp-sa-dialogflow.iam.gserviceaccount.com` service account where is the number of the Telephony Gateway project (usually the same as the Dialogflow agent project). If the Google Cloud Storage bucket is in the Telephony Gateway project, this permission is added by default when enabling the Dialogflow V2 API. For audio from other sources, consider using the `TelephonySynthesizeSpeech` message with SSML.",
          "type": "string"
        }
      }
    },
    "GoogleCloudDialogflowV2beta1IntentMessageRbmText": {
      "description": "Rich Business Messaging (RBM) text response with suggestions.",
      "type": "object",
      "properties": {
        "text": {
          "description": "Required. Text sent and displayed to the user.",
          "type": "string"
        },
        "rbmSuggestion": {
          "items": {
            "$ref": "GoogleCloudDialogflowV2beta1IntentMessageRbmSuggestion"
          },
          "description": "Optional. One or more suggestions to show to the user.",
          "type": "array"
        }
      },
      "id": "GoogleCloudDialogflowV2beta1IntentMessageRbmText"
    },
    "GoogleCloudDialogflowV2IntentMessageSimpleResponse": {
      "description": "The simple response message containing speech or text.",
      "type": "object",
      "id": "GoogleCloudDialogflowV2IntentMessageSimpleResponse",
      "properties": {
        "displayText": {
          "description": "Optional. The text to display.",
          "type": "string"
        },
        "ssml": {
          "description": "One of text_to_speech or ssml must be provided. Structured spoken response to the user in the SSML format. Mutually exclusive with text_to_speech.",
          "type": "string"
        },
        "textToSpeech": {
          "type": "string",
          "description": "One of text_to_speech or ssml must be provided. The plain text of the speech output. Mutually exclusive with ssml."
        }
      }
    },
    "GoogleCloudDialogflowV2IntentMessageListSelect": {
      "id": "GoogleCloudDialogflowV2IntentMessageListSelect",
      "properties": {
        "title": {
          "description": "Optional. The overall title of the list.",
          "type": "string"
        },
        "items": {
          "description": "Required. List items.",
          "type": "array",
          "items": {
            "$ref": "GoogleCloudDialogflowV2IntentMessageListSelectItem"
          }
        },
        "subtitle": {
          "type": "string",
          "description": "Optional. Subtitle of the list."
        }
      },
      "description": "The card for presenting a list of options to select from.",
      "type": "object"
    },
    "GoogleCloudDialogflowV2beta1IntentMessageListSelect": {
      "description": "The card for presenting a list of options to select from.",
      "id": "GoogleCloudDialogflowV2beta1IntentMessageListSelect",
      "type": "object",
      "properties": {
        "items": {
          "description": "Required. List items.",
          "items": {
            "$ref": "GoogleCloudDialogflowV2beta1IntentMessageListSelectItem"
          },
          "type": "array"
        },
        "title": {
          "type": "string",
          "description": "Optional. The overall title of the list."
        },
        "subtitle": {
          "type": "string",
          "description": "Optional. Subtitle of the list."
        }
      }
    },
    "GoogleCloudDialogflowV2beta1IntentMessageRbmStandaloneCard": {
      "id": "GoogleCloudDialogflowV2beta1IntentMessageRbmStandaloneCard",
      "description": "Standalone Rich Business Messaging (RBM) rich card. Rich cards allow you to respond to users with more vivid content, e.g. with media and suggestions. You can group multiple rich cards into one using RbmCarouselCard but carousel cards will give you less control over the card layout.",
      "properties": {
        "cardOrientation": {
          "enumDescriptions": [
            "Not specified.",
            "Horizontal layout.",
            "Vertical layout."
          ],
          "type": "string",
          "description": "Required. Orientation of the card.",
          "enum": [
            "CARD_ORIENTATION_UNSPECIFIED",
            "HORIZONTAL",
            "VERTICAL"
          ]
        },
        "cardContent": {
          "description": "Required. Card content.",
          "$ref": "GoogleCloudDialogflowV2beta1IntentMessageRbmCardContent"
        },
        "thumbnailImageAlignment": {
          "enumDescriptions": [
            "Not specified.",
            "Thumbnail preview is left-aligned.",
            "Thumbnail preview is right-aligned."
          ],
          "enum": [
            "THUMBNAIL_IMAGE_ALIGNMENT_UNSPECIFIED",
            "LEFT",
            "RIGHT"
          ],
          "description": "Required if orientation is horizontal. Image preview alignment for standalone cards with horizontal layout.",
          "type": "string"
        }
      },
      "type": "object"
    },
    "GoogleCloudDialogflowV2beta1IntentMessageCard": {
      "description": "The card response message.",
      "type": "object",
      "properties": {
        "imageUri": {
          "description": "Optional. The public URI to an image file for the card.",
          "type": "string"
        },
        "subtitle": {
          "description": "Optional. The subtitle of the card.",
          "type": "string"
        },
        "buttons": {
          "items": {
            "$ref": "GoogleCloudDialogflowV2beta1IntentMessageCardButton"
          },
          "description": "Optional. The collection of card buttons.",
          "type": "array"
        },
        "title": {
          "description": "Optional. The title of the card.",
          "type": "string"
        }
      },
      "id": "GoogleCloudDialogflowV2beta1IntentMessageCard"
    },
    "GoogleCloudDialogflowCxV3beta1PageInfoFormInfo": {
      "description": "Represents form information.",
      "id": "GoogleCloudDialogflowCxV3beta1PageInfoFormInfo",
      "type": "object",
      "properties": {
        "parameterInfo": {
          "items": {
            "$ref": "GoogleCloudDialogflowCxV3beta1PageInfoFormInfoParameterInfo"
          },
          "description": "Optional for both WebhookRequest and WebhookResponse. The parameters contained in the form. Note that the webhook cannot add or remove any form parameter.",
          "type": "array"
        }
      }
    },
    "GoogleCloudDialogflowV2beta1IntentMessageRbmSuggestedActionRbmSuggestedActionDial": {
      "properties": {
        "phoneNumber": {
          "description": "Required. The phone number to fill in the default dialer app. This field should be in [E.164](https://en.wikipedia.org/wiki/E.164) format. An example of a correctly formatted phone number: +15556767888.",
          "type": "string"
        }
      },
      "description": "Opens the user's default dialer app with the specified phone number but does not dial automatically.",
      "type": "object",
      "id": "GoogleCloudDialogflowV2beta1IntentMessageRbmSuggestedActionRbmSuggestedActionDial"
    },
    "GoogleCloudDialogflowV2beta1IntentMessage": {
      "properties": {
        "simpleResponses": {
          "description": "Returns a voice or text-only response for Actions on Google.",
          "$ref": "GoogleCloudDialogflowV2beta1IntentMessageSimpleResponses"
        },
        "payload": {
          "additionalProperties": {
            "description": "Properties of the object.",
            "type": "any"
          },
          "description": "A custom platform-specific response.",
          "type": "object"
        },
        "linkOutSuggestion": {
          "$ref": "GoogleCloudDialogflowV2beta1IntentMessageLinkOutSuggestion",
          "description": "Displays a link out suggestion chip for Actions on Google."
        },
        "image": {
          "$ref": "GoogleCloudDialogflowV2beta1IntentMessageImage",
          "description": "Displays an image."
        },
        "suggestions": {
          "$ref": "GoogleCloudDialogflowV2beta1IntentMessageSuggestions",
          "description": "Displays suggestion chips for Actions on Google."
        },
        "carouselSelect": {
          "$ref": "GoogleCloudDialogflowV2beta1IntentMessageCarouselSelect",
          "description": "Displays a carousel card for Actions on Google."
        },
        "telephonySynthesizeSpeech": {
          "$ref": "GoogleCloudDialogflowV2beta1IntentMessageTelephonySynthesizeSpeech",
          "description": "Synthesizes speech in Telephony Gateway."
        },
        "platform": {
          "enumDescriptions": [
            "Not specified.",
            "Facebook.",
            "Slack.",
            "Telegram.",
            "Kik.",
            "Skype.",
            "Line.",
            "Viber.",
            "Google Assistant See [Dialogflow webhook format](https://developers.google.com/assistant/actions/build/json/dialogflow-webhook-json)",
            "Telephony Gateway.",
            "Google Hangouts."
          ],
          "description": "Optional. The platform that this message is intended for.",
          "enum": [
            "PLATFORM_UNSPECIFIED",
            "FACEBOOK",
            "SLACK",
            "TELEGRAM",
            "KIK",
            "SKYPE",
            "LINE",
            "VIBER",
            "ACTIONS_ON_GOOGLE",
            "TELEPHONY",
            "GOOGLE_HANGOUTS"
          ],
          "type": "string"
        },
        "card": {
          "$ref": "GoogleCloudDialogflowV2beta1IntentMessageCard",
          "description": "Displays a card."
        },
        "telephonyPlayAudio": {
          "description": "Plays audio from a file in Telephony Gateway.",
          "$ref": "GoogleCloudDialogflowV2beta1IntentMessageTelephonyPlayAudio"
        },
        "rbmText": {
          "description": "Rich Business Messaging (RBM) text response. RBM allows businesses to send enriched and branded versions of SMS. See https://jibe.google.com/business-messaging.",
          "$ref": "GoogleCloudDialogflowV2beta1IntentMessageRbmText"
        },
        "rbmCarouselRichCard": {
          "description": "Rich Business Messaging (RBM) carousel rich card response.",
          "$ref": "GoogleCloudDialogflowV2beta1IntentMessageRbmCarouselCard"
        },
        "tableCard": {
          "$ref": "GoogleCloudDialogflowV2beta1IntentMessageTableCard",
          "description": "Table card for Actions on Google."
        },
        "telephonyTransferCall": {
          "$ref": "GoogleCloudDialogflowV2beta1IntentMessageTelephonyTransferCall",
          "description": "Transfers the call in Telephony Gateway."
        },
        "rbmStandaloneRichCard": {
          "$ref": "GoogleCloudDialogflowV2beta1IntentMessageRbmStandaloneCard",
          "description": "Standalone Rich Business Messaging (RBM) rich card response."
        },
        "mediaContent": {
          "description": "The media content card for Actions on Google.",
          "$ref": "GoogleCloudDialogflowV2beta1IntentMessageMediaContent"
        },
        "listSelect": {
          "$ref": "GoogleCloudDialogflowV2beta1IntentMessageListSelect",
          "description": "Displays a list card for Actions on Google."
        },
        "browseCarouselCard": {
          "$ref": "GoogleCloudDialogflowV2beta1IntentMessageBrowseCarouselCard",
          "description": "Browse carousel card for Actions on Google."
        },
        "basicCard": {
          "$ref": "GoogleCloudDialogflowV2beta1IntentMessageBasicCard",
          "description": "Displays a basic card for Actions on Google."
        },
        "quickReplies": {
          "$ref": "GoogleCloudDialogflowV2beta1IntentMessageQuickReplies",
          "description": "Displays quick replies."
        },
        "text": {
          "description": "Returns a text response.",
          "$ref": "GoogleCloudDialogflowV2beta1IntentMessageText"
        }
      },
      "id": "GoogleCloudDialogflowV2beta1IntentMessage",
      "description": "Corresponds to the `Response` field in the Dialogflow console.",
      "type": "object"
    },
    "GoogleCloudDialogflowCxV3beta1WebhookRequestIntentInfoIntentParameterValue": {
      "type": "object",
      "id": "GoogleCloudDialogflowCxV3beta1WebhookRequestIntentInfoIntentParameterValue",
      "properties": {
        "resolvedValue": {
          "type": "any",
          "description": "Always present. Structured value for the parameter extracted from user utterance."
        },
        "originalValue": {
          "description": "Always present. Original text value extracted from user utterance.",
          "type": "string"
        }
      },
      "description": "Represents a value for an intent parameter."
    },
    "GoogleCloudDialogflowV2beta1Context": {
      "description": "Dialogflow contexts are similar to natural language context. If a person says to you \"they are orange\", you need context in order to understand what \"they\" is referring to. Similarly, for Dialogflow to handle an end-user expression like that, it needs to be provided with context in order to correctly match an intent. Using contexts, you can control the flow of a conversation. You can configure contexts for an intent by setting input and output contexts, which are identified by string names. When an intent is matched, any configured output contexts for that intent become active. While any contexts are active, Dialogflow is more likely to match intents that are configured with input contexts that correspond to the currently active contexts. For more information about context, see the [Contexts guide](https://cloud.google.com/dialogflow/docs/contexts-overview).",
      "properties": {
        "parameters": {
          "type": "object",
          "description": "Optional. The collection of parameters associated with this context. Depending on your protocol or client library language, this is a map, associative array, symbol table, dictionary, or JSON object composed of a collection of (MapKey, MapValue) pairs: - MapKey type: string - MapKey value: parameter name - MapValue type: - If parameter's entity type is a composite entity: map - Else: string or number, depending on parameter value type - MapValue value: - If parameter's entity type is a composite entity: map from composite entity property names to property values - Else: parameter value",
          "additionalProperties": {
            "description": "Properties of the object.",
            "type": "any"
          }
        },
        "name": {
          "description": "Required. The unique identifier of the context. Format: `projects//agent/sessions//contexts/`, or `projects//agent/environments//users//sessions//contexts/`. The `Context ID` is always converted to lowercase, may only contain characters in a-zA-Z0-9_-% and may be at most 250 bytes long. If `Environment ID` is not specified, we assume default 'draft' environment. If `User ID` is not specified, we assume default '-' user. The following context names are reserved for internal use by Dialogflow. You should not use these contexts or create contexts with these names: * `__system_counters__` * `*_id_dialog_context` * `*_dialog_params_size`",
          "type": "string"
        },
        "lifespanCount": {
          "description": "Optional. The number of conversational query requests after which the context expires. The default is `0`. If set to `0`, the context expires immediately. Contexts expire automatically after 20 minutes if there are no matching queries.",
          "format": "int32",
          "type": "integer"
        }
      },
      "type": "object",
      "id": "GoogleCloudDialogflowV2beta1Context"
    },
    "GoogleCloudDialogflowV2IntentMessageCard": {
      "type": "object",
      "properties": {
        "title": {
          "type": "string",
          "description": "Optional. The title of the card."
        },
        "buttons": {
          "description": "Optional. The collection of card buttons.",
          "items": {
            "$ref": "GoogleCloudDialogflowV2IntentMessageCardButton"
          },
          "type": "array"
        },
        "subtitle": {
          "type": "string",
          "description": "Optional. The subtitle of the card."
        },
        "imageUri": {
          "type": "string",
          "description": "Optional. The public URI to an image file for the card."
        }
      },
      "description": "The card response message.",
      "id": "GoogleCloudDialogflowV2IntentMessageCard"
    },
    "GoogleCloudDialogflowV2IntentMessageBrowseCarouselCardBrowseCarouselCardItemOpenUrlAction": {
      "type": "object",
      "description": "Actions on Google action to open a given url.",
      "id": "GoogleCloudDialogflowV2IntentMessageBrowseCarouselCardBrowseCarouselCardItemOpenUrlAction",
      "properties": {
        "urlTypeHint": {
          "type": "string",
          "description": "Optional. Specifies the type of viewer that is used when opening the URL. Defaults to opening via web browser.",
          "enum": [
            "URL_TYPE_HINT_UNSPECIFIED",
            "AMP_ACTION",
            "AMP_CONTENT"
          ],
          "enumDescriptions": [
            "Unspecified",
            "Url would be an amp action",
            "URL that points directly to AMP content, or to a canonical URL which refers to AMP content via ."
          ]
        },
        "url": {
          "description": "Required. URL",
          "type": "string"
        }
      }
    },
    "GoogleCloudDialogflowV2beta1EntityTypeEntity": {
      "id": "GoogleCloudDialogflowV2beta1EntityTypeEntity",
      "properties": {
        "synonyms": {
          "type": "array",
          "description": "Required. A collection of value synonyms. For example, if the entity type is *vegetable*, and `value` is *scallions*, a synonym could be *green onions*. For `KIND_LIST` entity types: * This collection must contain exactly one synonym equal to `value`.",
          "items": {
            "type": "string"
          }
        },
        "value": {
          "type": "string",
          "description": "Required. The primary value associated with this entity entry. For example, if the entity type is *vegetable*, the value could be *scallions*. For `KIND_MAP` entity types: * A reference value to be used in place of synonyms. For `KIND_LIST` entity types: * A string that can contain references to other entity types (with or without aliases)."
        }
      },
      "type": "object",
      "description": "An **entity entry** for an associated entity type."
    },
    "GoogleCloudDialogflowV2IntentMessageBrowseCarouselCard": {
      "description": "Browse Carousel Card for Actions on Google. https://developers.google.com/actions/assistant/responses#browsing_carousel",
      "properties": {
        "items": {
          "items": {
            "$ref": "GoogleCloudDialogflowV2IntentMessageBrowseCarouselCardBrowseCarouselCardItem"
          },
          "description": "Required. List of items in the Browse Carousel Card. Minimum of two items, maximum of ten.",
          "type": "array"
        },
        "imageDisplayOptions": {
          "enum": [
            "IMAGE_DISPLAY_OPTIONS_UNSPECIFIED",
            "GRAY",
            "WHITE",
            "CROPPED",
            "BLURRED_BACKGROUND"
          ],
          "description": "Optional. Settings for displaying the image. Applies to every image in items.",
          "type": "string",
          "enumDescriptions": [
            "Fill the gaps between the image and the image container with gray bars.",
            "Fill the gaps between the image and the image container with gray bars.",
            "Fill the gaps between the image and the image container with white bars.",
            "Image is scaled such that the image width and height match or exceed the container dimensions. This may crop the top and bottom of the image if the scaled image height is greater than the container height, or crop the left and right of the image if the scaled image width is greater than the container width. This is similar to \"Zoom Mode\" on a widescreen TV when playing a 4:3 video.",
            "Pad the gaps between image and image frame with a blurred copy of the same image."
          ]
        }
      },
      "id": "GoogleCloudDialogflowV2IntentMessageBrowseCarouselCard",
      "type": "object"
    },
    "GoogleCloudDialogflowV2beta1IntentMessageCardButton": {
      "description": "Optional. Contains information about a button.",
      "properties": {
        "postback": {
          "description": "Optional. The text to send back to the Dialogflow API or a URI to open.",
          "type": "string"
        },
        "text": {
          "description": "Optional. The text to show on the button.",
          "type": "string"
        }
      },
      "type": "object",
      "id": "GoogleCloudDialogflowV2beta1IntentMessageCardButton"
    },
    "GoogleCloudDialogflowCxV3beta1ResponseMessageEndInteraction": {
      "description": "Indicates that interaction with the Dialogflow agent has ended. This message is generated by Dialogflow only and not supposed to be defined by the user.",
      "properties": {},
      "type": "object",
      "id": "GoogleCloudDialogflowCxV3beta1ResponseMessageEndInteraction"
    },
    "GoogleCloudDialogflowV2beta1OriginalDetectIntentRequest": {
      "properties": {
        "payload": {
          "type": "object",
          "description": "Optional. This field is set to the value of the `QueryParameters.payload` field passed in the request. Some integrations that query a Dialogflow agent may provide additional information in the payload. In particular, for the Dialogflow Phone Gateway integration, this field has the form: { \"telephony\": { \"caller_id\": \"+18558363987\" } } Note: The caller ID field (`caller_id`) will be redacted for Standard Edition agents and populated with the caller ID in [E.164 format](https://en.wikipedia.org/wiki/E.164) for Enterprise Edition agents.",
          "additionalProperties": {
            "description": "Properties of the object.",
            "type": "any"
          }
        },
        "version": {
          "type": "string",
          "description": "Optional. The version of the protocol used for this request. This field is AoG-specific."
        },
        "source": {
          "type": "string",
          "description": "The source of this request, e.g., `google`, `facebook`, `slack`. It is set by Dialogflow-owned servers."
        }
      },
      "type": "object",
      "description": "Represents the contents of the original request that was passed to the `[Streaming]DetectIntent` call.",
      "id": "GoogleCloudDialogflowV2beta1OriginalDetectIntentRequest"
    },
    "GoogleCloudDialogflowCxV3beta1SessionInfo": {
      "description": "Represents session information communicated to and from the webhook.",
      "id": "GoogleCloudDialogflowCxV3beta1SessionInfo",
      "properties": {
        "session": {
          "type": "string",
          "description": "Always present for WebhookRequest. Ignored for WebhookResponse. The unique identifier of the session. This field can be used by the webhook to identify a user. Format: `projects//locations//agents//sessions/`."
        },
        "parameters": {
          "type": "object",
          "additionalProperties": {
            "type": "any"
          },
          "description": "Optional for WebhookRequest. Optional for WebhookResponse. All parameters collected from forms and intents during the session. Parameters can be created, updated, or removed by the webhook. To remove a parameter from the session, the webhook should explicitly set the parameter value to null in WebhookResponse. The map is keyed by parameters' display names."
        }
      },
      "type": "object"
    },
    "GoogleCloudDialogflowV2IntentMessageMediaContentResponseMediaObject": {
      "properties": {
        "largeImage": {
          "$ref": "GoogleCloudDialogflowV2IntentMessageImage",
          "description": "Optional. Image to display above media content."
        },
        "contentUrl": {
          "type": "string",
          "description": "Required. Url where the media is stored."
        },
        "icon": {
          "description": "Optional. Icon to display above media content.",
          "$ref": "GoogleCloudDialogflowV2IntentMessageImage"
        },
        "description": {
          "type": "string",
          "description": "Optional. Description of media card."
        },
        "name": {
          "description": "Required. Name of media card.",
          "type": "string"
        }
      },
      "description": "Response media object for media content card.",
      "id": "GoogleCloudDialogflowV2IntentMessageMediaContentResponseMediaObject",
      "type": "object"
    },
    "GoogleCloudDialogflowV2beta1BatchUpdateEntityTypesResponse": {
      "description": "The response message for EntityTypes.BatchUpdateEntityTypes.",
      "properties": {
        "entityTypes": {
          "type": "array",
          "items": {
            "$ref": "GoogleCloudDialogflowV2beta1EntityType"
          },
          "description": "The collection of updated or created entity types."
        }
      },
      "type": "object",
      "id": "GoogleCloudDialogflowV2beta1BatchUpdateEntityTypesResponse"
    },
    "GoogleCloudDialogflowV2beta1IntentMessageSelectItemInfo": {
      "id": "GoogleCloudDialogflowV2beta1IntentMessageSelectItemInfo",
      "description": "Additional info about the select item for when it is triggered in a dialog.",
      "properties": {
        "synonyms": {
          "items": {
            "type": "string"
          },
          "type": "array",
          "description": "Optional. A list of synonyms that can also be used to trigger this item in dialog."
        },
        "key": {
          "type": "string",
          "description": "Required. A unique key that will be sent back to the agent if this response is given."
        }
      },
      "type": "object"
    },
    "GoogleCloudDialogflowV2IntentMessageColumnProperties": {
      "properties": {
        "header": {
          "type": "string",
          "description": "Required. Column heading."
        },
        "horizontalAlignment": {
          "enumDescriptions": [
            "Text is aligned to the leading edge of the column.",
            "Text is aligned to the leading edge of the column.",
            "Text is centered in the column.",
            "Text is aligned to the trailing edge of the column."
          ],
          "enum": [
            "HORIZONTAL_ALIGNMENT_UNSPECIFIED",
            "LEADING",
            "CENTER",
            "TRAILING"
          ],
          "type": "string",
          "description": "Optional. Defines text alignment for all cells in this column."
        }
      },
      "id": "GoogleCloudDialogflowV2IntentMessageColumnProperties",
      "type": "object",
      "description": "Column properties for TableCard."
    },
    "GoogleCloudDialogflowCxV3beta1PageInfoFormInfoParameterInfo": {
      "id": "GoogleCloudDialogflowCxV3beta1PageInfoFormInfoParameterInfo",
      "type": "object",
      "description": "Represents parameter information.",
      "properties": {
        "value": {
          "type": "any",
          "description": "Optional for both WebhookRequest and WebhookResponse. The value of the parameter. This field can be set by the webhook to change the parameter value."
        },
        "required": {
          "description": "Optional for both WebhookRequest and WebhookResponse. Indicates whether the parameter is required. Optional parameters will not trigger prompts; however, they are filled if the user specifies them. Required parameters must be filled before form filling concludes.",
          "type": "boolean"
        },
        "state": {
          "description": "Always present for WebhookRequest. Required for WebhookResponse. The state of the parameter. This field can be set to INVALID by the webhook to invalidate the parameter; other values set by the webhook will be ignored.",
          "enum": [
            "PARAMETER_STATE_UNSPECIFIED",
            "EMPTY",
            "INVALID",
            "FILLED"
          ],
          "enumDescriptions": [
            "Not specified. This value should be never used.",
            "Indicates that the parameter does not have a value.",
            "Indicates that the parameter value is invalid. This field can be used by the webhook to invalidate the parameter and ask the server to collect it from the user again.",
            "Indicates that the parameter has a value."
          ],
          "type": "string"
        },
        "displayName": {
          "description": "Always present for WebhookRequest. Required for WebhookResponse. The human-readable name of the parameter, unique within the form. This field cannot be modified by the webhook.",
          "type": "string"
        },
        "justCollected": {
          "type": "boolean",
          "description": "Optional for WebhookRequest. Ignored for WebhookResponse. Indicates if the parameter value was just collected on the last conversation turn."
        }
      }
    },
    "GoogleCloudDialogflowV2beta1IntentMessageSimpleResponse": {
      "properties": {
        "textToSpeech": {
          "type": "string",
          "description": "One of text_to_speech or ssml must be provided. The plain text of the speech output. Mutually exclusive with ssml."
        },
        "ssml": {
          "description": "One of text_to_speech or ssml must be provided. Structured spoken response to the user in the SSML format. Mutually exclusive with text_to_speech.",
          "type": "string"
        },
        "displayText": {
          "type": "string",
          "description": "Optional. The text to display."
        }
      },
      "id": "GoogleCloudDialogflowV2beta1IntentMessageSimpleResponse",
      "type": "object",
      "description": "The simple response message containing speech or text."
    },
    "GoogleCloudDialogflowV2beta1AnnotatedConversationDataset": {
      "id": "GoogleCloudDialogflowV2beta1AnnotatedConversationDataset",
      "description": "Represents an annotated conversation dataset. ConversationDataset can have multiple AnnotatedConversationDataset, each of them represents one result from one annotation task. AnnotatedConversationDataset can only be generated from annotation task, which will be triggered by LabelConversation.",
      "properties": {
        "completedExampleCount": {
          "format": "int64",
          "description": "Output only. Number of examples that have annotations in the annotated conversation dataset.",
          "type": "string",
          "readOnly": true
        },
        "displayName": {
          "type": "string",
          "description": "Required. The display name of the annotated conversation dataset. It's specified when user starts an annotation task. Maximum of 64 bytes."
        },
        "questionTypeName": {
          "description": "Output only. Question type name that identifies a labeling task. A question is a single task that a worker answers. A question type is set of related questions. Each question belongs to a particular question type. It can be used in CrowdCompute UI to filter and manage labeling tasks.",
          "type": "string",
          "readOnly": true
        },
        "exampleCount": {
          "readOnly": true,
          "format": "int64",
          "type": "string",
          "description": "Output only. Number of examples in the annotated conversation dataset."
        },
        "description": {
          "type": "string",
          "description": "Optional. The description of the annotated conversation dataset. Maximum of 10000 bytes."
        },
        "name": {
          "readOnly": true,
          "type": "string",
          "description": "Output only. AnnotatedConversationDataset resource name. Format: `projects//conversationDatasets//annotatedConversationDatasets/`"
        },
        "createTime": {
          "readOnly": true,
          "description": "Output only. Creation time of this annotated conversation dataset.",
          "format": "google-datetime",
          "type": "string"
        }
      },
      "type": "object"
    },
    "GoogleCloudDialogflowCxV3beta1ResponseMessageLiveAgentHandoff": {
      "properties": {
        "metadata": {
          "type": "object",
          "description": "Custom metadata for your handoff procedure. Dialogflow doesn't impose any structure on this.",
          "additionalProperties": {
            "description": "Properties of the object.",
            "type": "any"
          }
        }
      },
      "id": "GoogleCloudDialogflowCxV3beta1ResponseMessageLiveAgentHandoff",
      "description": "Indicates that the conversation should be handed off to a live agent. Dialogflow only uses this to determine which conversations were handed off to a human agent for measurement purposes. What else to do with this signal is up to you and your handoff procedures. You may set this, for example: * In the entry_fulfillment of a Page if entering the page indicates something went extremely wrong in the conversation. * In a webhook response when you determine that the customer issue can only be handled by a human.",
      "type": "object"
    },
    "GoogleCloudDialogflowCxV3beta1ResponseMessageMixedAudioSegment": {
      "id": "GoogleCloudDialogflowCxV3beta1ResponseMessageMixedAudioSegment",
      "properties": {
        "allowPlaybackInterruption": {
          "description": "Output only. Whether the playback of this segment can be interrupted by the end user's speech and the client should then start the next Dialogflow request.",
          "readOnly": true,
          "type": "boolean"
        },
        "uri": {
          "description": "Client-specific URI that points to an audio clip accessible to the client. Dialogflow does not impose any validation on it.",
          "type": "string"
        },
        "audio": {
          "description": "Raw audio synthesized from the Dialogflow agent's response using the output config specified in the request.",
          "type": "string",
          "format": "byte"
        }
      },
      "description": "Represents one segment of audio.",
      "type": "object"
    },
    "GoogleCloudDialogflowV2beta1IntentMessageTelephonySynthesizeSpeech": {
      "properties": {
        "text": {
          "type": "string",
          "description": "The raw text to be synthesized."
        },
        "ssml": {
          "type": "string",
          "description": "The SSML to be synthesized. For more information, see [SSML](https://developers.google.com/actions/reference/ssml)."
        }
      },
      "type": "object",
      "description": "Synthesizes speech and plays back the synthesized audio to the caller in Telephony Gateway. Telephony Gateway takes the synthesizer settings from `DetectIntentResponse.output_audio_config` which can either be set at request-level or can come from the agent-level synthesizer config.",
      "id": "GoogleCloudDialogflowV2beta1IntentMessageTelephonySynthesizeSpeech"
    },
    "GoogleCloudDialogflowV2IntentMessageText": {
      "description": "The text response message.",
      "type": "object",
      "properties": {
        "text": {
          "type": "array",
          "description": "Optional. The collection of the agent's responses.",
          "items": {
            "type": "string"
          }
        }
      },
      "id": "GoogleCloudDialogflowV2IntentMessageText"
    },
    "GoogleCloudDialogflowV2IntentFollowupIntentInfo": {
      "id": "GoogleCloudDialogflowV2IntentFollowupIntentInfo",
      "description": "Represents a single followup intent in the chain.",
      "properties": {
        "followupIntentName": {
          "type": "string",
          "description": "The unique identifier of the followup intent. Format: `projects//agent/intents/`."
        },
        "parentFollowupIntentName": {
          "description": "The unique identifier of the followup intent's parent. Format: `projects//agent/intents/`.",
          "type": "string"
        }
      },
      "type": "object"
    },
    "GoogleCloudDialogflowV2IntentMessageBasicCardButtonOpenUriAction": {
      "type": "object",
      "id": "GoogleCloudDialogflowV2IntentMessageBasicCardButtonOpenUriAction",
      "properties": {
        "uri": {
          "type": "string",
          "description": "Required. The HTTP or HTTPS scheme URI."
        }
      },
      "description": "Opens the given URI."
    },
    "GoogleCloudDialogflowV2beta1EntityType": {
      "properties": {
        "displayName": {
          "description": "Required. The name of the entity type.",
          "type": "string"
        },
        "kind": {
          "enum": [
            "KIND_UNSPECIFIED",
            "KIND_MAP",
            "KIND_LIST",
            "KIND_REGEXP"
          ],
          "enumDescriptions": [
            "Not specified. This value should be never used.",
            "Map entity types allow mapping of a group of synonyms to a reference value.",
            "List entity types contain a set of entries that do not map to reference values. However, list entity types can contain references to other entity types (with or without aliases).",
            "Regexp entity types allow to specify regular expressions in entries values."
          ],
          "description": "Required. Indicates the kind of entity type.",
          "type": "string"
        },
        "entities": {
          "description": "Optional. The collection of entity entries associated with the entity type.",
          "items": {
            "$ref": "GoogleCloudDialogflowV2beta1EntityTypeEntity"
          },
          "type": "array"
        },
        "autoExpansionMode": {
          "description": "Optional. Indicates whether the entity type can be automatically expanded.",
          "enumDescriptions": [
            "Auto expansion disabled for the entity.",
            "Allows an agent to recognize values that have not been explicitly listed in the entity."
          ],
          "type": "string",
          "enum": [
            "AUTO_EXPANSION_MODE_UNSPECIFIED",
            "AUTO_EXPANSION_MODE_DEFAULT"
          ]
        },
        "name": {
          "description": "The unique identifier of the entity type. Required for EntityTypes.UpdateEntityType and EntityTypes.BatchUpdateEntityTypes methods. Format: `projects//agent/entityTypes/`.",
          "type": "string"
        },
        "enableFuzzyExtraction": {
          "description": "Optional. Enables fuzzy entity extraction during classification.",
          "type": "boolean"
        }
      },
      "id": "GoogleCloudDialogflowV2beta1EntityType",
      "type": "object",
      "description": "Each intent parameter has a type, called the entity type, which dictates exactly how data from an end-user expression is extracted. Dialogflow provides predefined system entities that can match many common types of data. For example, there are system entities for matching dates, times, colors, email addresses, and so on. You can also create your own custom entities for matching custom data. For example, you could define a vegetable entity that can match the types of vegetables available for purchase with a grocery store agent. For more information, see the [Entity guide](https://cloud.google.com/dialogflow/docs/entities-overview)."
    },
    "GoogleCloudDialogflowV2beta1IntentMessageSuggestions": {
      "description": "The collection of suggestions.",
      "id": "GoogleCloudDialogflowV2beta1IntentMessageSuggestions",
      "properties": {
        "suggestions": {
          "items": {
            "$ref": "GoogleCloudDialogflowV2beta1IntentMessageSuggestion"
          },
          "description": "Required. The list of suggested replies.",
          "type": "array"
        }
      },
      "type": "object"
    },
    "GoogleCloudDialogflowV2IntentMessageImage": {
      "description": "The image response message.",
      "type": "object",
      "properties": {
        "accessibilityText": {
          "description": "Optional. A text description of the image to be used for accessibility, e.g., screen readers.",
          "type": "string"
        },
        "imageUri": {
          "type": "string",
          "description": "Optional. The public URI to an image file."
        }
      },
      "id": "GoogleCloudDialogflowV2IntentMessageImage"
    },
    "GoogleCloudDialogflowV2beta1IntentMessageLinkOutSuggestion": {
      "description": "The suggestion chip message that allows the user to jump out to the app or website associated with this agent.",
      "id": "GoogleCloudDialogflowV2beta1IntentMessageLinkOutSuggestion",
      "type": "object",
      "properties": {
        "destinationName": {
          "description": "Required. The name of the app or site this chip is linking to.",
          "type": "string"
        },
        "uri": {
          "description": "Required. The URI of the app or site to open when the user taps the suggestion chip.",
          "type": "string"
        }
      }
    },
    "GoogleCloudDialogflowV2beta1IntentMessageBasicCardButtonOpenUriAction": {
      "description": "Opens the given URI.",
      "id": "GoogleCloudDialogflowV2beta1IntentMessageBasicCardButtonOpenUriAction",
      "properties": {
        "uri": {
          "type": "string",
          "description": "Required. The HTTP or HTTPS scheme URI."
        }
      },
      "type": "object"
    },
    "GoogleCloudDialogflowV2beta1IntentTrainingPhrase": {
      "properties": {
        "type": {
          "description": "Required. The type of the training phrase.",
          "enumDescriptions": [
            "Not specified. This value should never be used.",
            "Examples do not contain @-prefixed entity type names, but example parts can be annotated with entity types.",
            "Templates are not annotated with entity types, but they can contain @-prefixed entity type names as substrings. Template mode has been deprecated. Example mode is the only supported way to create new training phrases. If you have existing training phrases that you've created in template mode, those will continue to work."
          ],
          "type": "string",
          "enum": [
            "TYPE_UNSPECIFIED",
            "EXAMPLE",
            "TEMPLATE"
          ]
        },
        "parts": {
          "type": "array",
          "items": {
            "$ref": "GoogleCloudDialogflowV2beta1IntentTrainingPhrasePart"
          },
          "description": "Required. The ordered list of training phrase parts. The parts are concatenated in order to form the training phrase. Note: The API does not automatically annotate training phrases like the Dialogflow Console does. Note: Do not forget to include whitespace at part boundaries, so the training phrase is well formatted when the parts are concatenated. If the training phrase does not need to be annotated with parameters, you just need a single part with only the Part.text field set. If you want to annotate the training phrase, you must create multiple parts, where the fields of each part are populated in one of two ways: - `Part.text` is set to a part of the phrase that has no parameters. - `Part.text` is set to a part of the phrase that you want to annotate, and the `entity_type`, `alias`, and `user_defined` fields are all set."
        },
        "name": {
          "type": "string",
          "description": "Output only. The unique identifier of this training phrase."
        },
        "timesAddedCount": {
          "description": "Optional. Indicates how many times this example was added to the intent. Each time a developer adds an existing sample by editing an intent or training, this counter is increased.",
          "type": "integer",
          "format": "int32"
        }
      },
      "type": "object",
      "description": "Represents an example that the agent is trained on.",
      "id": "GoogleCloudDialogflowV2beta1IntentTrainingPhrase"
    },
    "GoogleCloudDialogflowV2beta1IntentMessageBrowseCarouselCardBrowseCarouselCardItemOpenUrlAction": {
      "properties": {
        "urlTypeHint": {
          "enum": [
            "URL_TYPE_HINT_UNSPECIFIED",
            "AMP_ACTION",
            "AMP_CONTENT"
          ],
          "description": "Optional. Specifies the type of viewer that is used when opening the URL. Defaults to opening via web browser.",
          "enumDescriptions": [
            "Unspecified",
            "Url would be an amp action",
            "URL that points directly to AMP content, or to a canonical URL which refers to AMP content via ."
          ],
          "type": "string"
        },
        "url": {
          "type": "string",
          "description": "Required. URL"
        }
      },
      "description": "Actions on Google action to open a given url.",
      "id": "GoogleCloudDialogflowV2beta1IntentMessageBrowseCarouselCardBrowseCarouselCardItemOpenUrlAction",
      "type": "object"
    },
    "GoogleCloudDialogflowV2beta1IntentMessageTableCard": {
      "type": "object",
      "properties": {
        "rows": {
          "description": "Optional. Rows in this table of data.",
          "items": {
            "$ref": "GoogleCloudDialogflowV2beta1IntentMessageTableCardRow"
          },
          "type": "array"
        },
        "columnProperties": {
          "type": "array",
          "description": "Optional. Display properties for the columns in this table.",
          "items": {
            "$ref": "GoogleCloudDialogflowV2beta1IntentMessageColumnProperties"
          }
        },
        "image": {
          "$ref": "GoogleCloudDialogflowV2beta1IntentMessageImage",
          "description": "Optional. Image which should be displayed on the card."
        },
        "subtitle": {
          "type": "string",
          "description": "Optional. Subtitle to the title."
        },
        "title": {
          "type": "string",
          "description": "Required. Title of the card."
        },
        "buttons": {
          "items": {
            "$ref": "GoogleCloudDialogflowV2beta1IntentMessageBasicCardButton"
          },
          "description": "Optional. List of buttons for the card.",
          "type": "array"
        }
      },
      "id": "GoogleCloudDialogflowV2beta1IntentMessageTableCard",
      "description": "Table card for Actions on Google."
    },
    "GoogleCloudDialogflowCxV3beta1ResponseMessageConversationSuccess": {
      "id": "GoogleCloudDialogflowCxV3beta1ResponseMessageConversationSuccess",
      "description": "Indicates that the conversation succeeded, i.e., the bot handled the issue that the customer talked to it about. Dialogflow only uses this to determine which conversations should be counted as successful and doesn't process the metadata in this message in any way. Note that Dialogflow also considers conversations that get to the conversation end page as successful even if they don't return ConversationSuccess. You may set this, for example: * In the entry_fulfillment of a Page if entering the page indicates that the conversation succeeded. * In a webhook response when you determine that you handled the customer issue.",
      "properties": {
        "metadata": {
          "type": "object",
          "additionalProperties": {
            "type": "any",
            "description": "Properties of the object."
          },
          "description": "Custom metadata. Dialogflow doesn't impose any structure on this."
        }
      },
      "type": "object"
    },
    "GoogleCloudDialogflowV2WebhookResponse": {
      "id": "GoogleCloudDialogflowV2WebhookResponse",
      "description": "The response message for a webhook call. This response is validated by the Dialogflow server. If validation fails, an error will be returned in the QueryResult.diagnostic_info field. Setting JSON fields to an empty value with the wrong type is a common error. To avoid this error: - Use `\"\"` for empty strings - Use `{}` or `null` for empty objects - Use `[]` or `null` for empty arrays For more information, see the [Protocol Buffers Language Guide](https://developers.google.com/protocol-buffers/docs/proto3#json).",
      "properties": {
        "followupEventInput": {
          "description": "Optional. Invokes the supplied events. When this field is set, Dialogflow ignores the `fulfillment_text`, `fulfillment_messages`, and `payload` fields.",
          "$ref": "GoogleCloudDialogflowV2EventInput"
        },
        "source": {
          "type": "string",
          "description": "Optional. A custom field used to identify the webhook source. Arbitrary strings are supported. When provided, Dialogflow uses this field to populate QueryResult.webhook_source sent to the integration or API caller."
        },
        "outputContexts": {
          "type": "array",
          "description": "Optional. The collection of output contexts that will overwrite currently active contexts for the session and reset their lifespans. When provided, Dialogflow uses this field to populate QueryResult.output_contexts sent to the integration or API caller.",
          "items": {
            "$ref": "GoogleCloudDialogflowV2Context"
          }
        },
        "fulfillmentText": {
          "type": "string",
          "description": "Optional. The text response message intended for the end-user. It is recommended to use `fulfillment_messages.text.text[0]` instead. When provided, Dialogflow uses this field to populate QueryResult.fulfillment_text sent to the integration or API caller."
        },
        "payload": {
          "additionalProperties": {
            "description": "Properties of the object.",
            "type": "any"
          },
          "description": "Optional. This field can be used to pass custom data from your webhook to the integration or API caller. Arbitrary JSON objects are supported. When provided, Dialogflow uses this field to populate QueryResult.webhook_payload sent to the integration or API caller. This field is also used by the [Google Assistant integration](https://cloud.google.com/dialogflow/docs/integrations/aog) for rich response messages. See the format definition at [Google Assistant Dialogflow webhook format](https://developers.google.com/assistant/actions/build/json/dialogflow-webhook-json)",
          "type": "object"
        },
        "fulfillmentMessages": {
          "type": "array",
          "description": "Optional. The rich response messages intended for the end-user. When provided, Dialogflow uses this field to populate QueryResult.fulfillment_messages sent to the integration or API caller.",
          "items": {
            "$ref": "GoogleCloudDialogflowV2IntentMessage"
          }
        },
        "sessionEntityTypes": {
          "items": {
            "$ref": "GoogleCloudDialogflowV2SessionEntityType"
          },
          "type": "array",
          "description": "Optional. Additional session entity types to replace or extend developer entity types with. The entity synonyms apply to all languages and persist for the session. Setting this data from a webhook overwrites the session entity types that have been set using `detectIntent`, `streamingDetectIntent` or SessionEntityType management methods."
        }
      },
      "type": "object"
    },
    "GoogleCloudDialogflowCxV3beta1ResponseMessageMixedAudio": {
      "properties": {
        "segments": {
          "description": "Segments this audio response is composed of.",
          "type": "array",
          "items": {
            "$ref": "GoogleCloudDialogflowCxV3beta1ResponseMessageMixedAudioSegment"
          }
        }
      },
      "type": "object",
      "id": "GoogleCloudDialogflowCxV3beta1ResponseMessageMixedAudio",
      "description": "Represents an audio message that is composed of both segments synthesized from the Dialogflow agent prompts and ones hosted externally at the specified URIs. The external URIs are specified via play_audio. This message is generated by Dialogflow only and not supposed to be defined by the user."
    },
    "GoogleCloudDialogflowV2IntentMessageBasicCardButton": {
      "description": "The button object that appears at the bottom of a card.",
      "id": "GoogleCloudDialogflowV2IntentMessageBasicCardButton",
      "properties": {
        "openUriAction": {
          "$ref": "GoogleCloudDialogflowV2IntentMessageBasicCardButtonOpenUriAction",
          "description": "Required. Action to take when a user taps on the button."
        },
        "title": {
          "description": "Required. The title of the button.",
          "type": "string"
        }
      },
      "type": "object"
    },
    "GoogleCloudDialogflowV2beta1SessionEntityType": {
      "type": "object",
      "id": "GoogleCloudDialogflowV2beta1SessionEntityType",
      "properties": {
        "entityOverrideMode": {
          "enum": [
            "ENTITY_OVERRIDE_MODE_UNSPECIFIED",
            "ENTITY_OVERRIDE_MODE_OVERRIDE",
            "ENTITY_OVERRIDE_MODE_SUPPLEMENT"
          ],
          "type": "string",
          "enumDescriptions": [
            "Not specified. This value should be never used.",
            "The collection of session entities overrides the collection of entities in the corresponding custom entity type.",
            "The collection of session entities extends the collection of entities in the corresponding custom entity type. Note: Even in this override mode calls to `ListSessionEntityTypes`, `GetSessionEntityType`, `CreateSessionEntityType` and `UpdateSessionEntityType` only return the additional entities added in this session entity type. If you want to get the supplemented list, please call EntityTypes.GetEntityType on the custom entity type and merge."
          ],
          "description": "Required. Indicates whether the additional data should override or supplement the custom entity type definition."
        },
        "name": {
          "description": "Required. The unique identifier of this session entity type. Format: `projects//agent/sessions//entityTypes/`, or `projects//agent/environments//users//sessions//entityTypes/`. If `Environment ID` is not specified, we assume default 'draft' environment. If `User ID` is not specified, we assume default '-' user. `` must be the display name of an existing entity type in the same agent that will be overridden or supplemented.",
          "type": "string"
        },
        "entities": {
          "type": "array",
          "items": {
            "$ref": "GoogleCloudDialogflowV2beta1EntityTypeEntity"
          },
          "description": "Required. The collection of entities associated with this session entity type."
        }
      },
      "description": "A session represents a conversation between a Dialogflow agent and an end-user. You can create special entities, called session entities, during a session. Session entities can extend or replace custom entity types and only exist during the session that they were created for. All session data, including session entities, is stored by Dialogflow for 20 minutes. For more information, see the [session entity guide](https://cloud.google.com/dialogflow/docs/entities-session)."
    },
    "GoogleCloudDialogflowCxV3beta1ResponseMessageText": {
      "type": "object",
      "description": "The text response message.",
      "properties": {
        "allowPlaybackInterruption": {
          "type": "boolean",
          "readOnly": true,
          "description": "Output only. Whether the playback of this message can be interrupted by the end user's speech and the client can then starts the next Dialogflow request."
        },
        "text": {
          "description": "Required. A collection of text responses.",
          "items": {
            "type": "string"
          },
          "type": "array"
        }
      },
      "id": "GoogleCloudDialogflowCxV3beta1ResponseMessageText"
    },
    "GoogleCloudDialogflowV2OriginalDetectIntentRequest": {
      "id": "GoogleCloudDialogflowV2OriginalDetectIntentRequest",
      "type": "object",
      "properties": {
        "version": {
          "description": "Optional. The version of the protocol used for this request. This field is AoG-specific.",
          "type": "string"
        },
        "source": {
          "type": "string",
          "description": "The source of this request, e.g., `google`, `facebook`, `slack`. It is set by Dialogflow-owned servers."
        },
        "payload": {
          "type": "object",
          "additionalProperties": {
            "type": "any",
            "description": "Properties of the object."
          },
          "description": "Optional. This field is set to the value of the `QueryParameters.payload` field passed in the request. Some integrations that query a Dialogflow agent may provide additional information in the payload. In particular, for the Dialogflow Phone Gateway integration, this field has the form: { \"telephony\": { \"caller_id\": \"+18558363987\" } } Note: The caller ID field (`caller_id`) will be redacted for Standard Edition agents and populated with the caller ID in [E.164 format](https://en.wikipedia.org/wiki/E.164) for Enterprise Edition agents."
        }
      },
      "description": "Represents the contents of the original request that was passed to the `[Streaming]DetectIntent` call."
    },
    "GoogleCloudDialogflowV2IntentMessageSelectItemInfo": {
      "description": "Additional info about the select item for when it is triggered in a dialog.",
      "id": "GoogleCloudDialogflowV2IntentMessageSelectItemInfo",
      "properties": {
        "key": {
          "description": "Required. A unique key that will be sent back to the agent if this response is given.",
          "type": "string"
        },
        "synonyms": {
          "items": {
            "type": "string"
          },
          "type": "array",
          "description": "Optional. A list of synonyms that can also be used to trigger this item in dialog."
        }
      },
      "type": "object"
    },
    "GoogleCloudDialogflowV2beta1IntentMessageRbmSuggestedAction": {
      "properties": {
        "openUrl": {
          "description": "Suggested client side action: Open a URI on device",
          "$ref": "GoogleCloudDialogflowV2beta1IntentMessageRbmSuggestedActionRbmSuggestedActionOpenUri"
        },
        "shareLocation": {
          "$ref": "GoogleCloudDialogflowV2beta1IntentMessageRbmSuggestedActionRbmSuggestedActionShareLocation",
          "description": "Suggested client side action: Share user location"
        },
        "dial": {
          "description": "Suggested client side action: Dial a phone number",
          "$ref": "GoogleCloudDialogflowV2beta1IntentMessageRbmSuggestedActionRbmSuggestedActionDial"
        },
        "text": {
          "description": "Text to display alongside the action.",
          "type": "string"
        },
        "postbackData": {
          "description": "Opaque payload that the Dialogflow receives in a user event when the user taps the suggested action. This data will be also forwarded to webhook to allow performing custom business logic.",
          "type": "string"
        }
      },
      "id": "GoogleCloudDialogflowV2beta1IntentMessageRbmSuggestedAction",
      "type": "object",
      "description": "Rich Business Messaging (RBM) suggested client-side action that the user can choose from the card."
    },
    "GoogleCloudDialogflowV2beta1IntentMessageBrowseCarouselCard": {
      "type": "object",
      "id": "GoogleCloudDialogflowV2beta1IntentMessageBrowseCarouselCard",
      "description": "Browse Carousel Card for Actions on Google. https://developers.google.com/actions/assistant/responses#browsing_carousel",
      "properties": {
        "items": {
          "description": "Required. List of items in the Browse Carousel Card. Minimum of two items, maximum of ten.",
          "type": "array",
          "items": {
            "$ref": "GoogleCloudDialogflowV2beta1IntentMessageBrowseCarouselCardBrowseCarouselCardItem"
          }
        },
        "imageDisplayOptions": {
          "type": "string",
          "enum": [
            "IMAGE_DISPLAY_OPTIONS_UNSPECIFIED",
            "GRAY",
            "WHITE",
            "CROPPED",
            "BLURRED_BACKGROUND"
          ],
          "enumDescriptions": [
            "Fill the gaps between the image and the image container with gray bars.",
            "Fill the gaps between the image and the image container with gray bars.",
            "Fill the gaps between the image and the image container with white bars.",
            "Image is scaled such that the image width and height match or exceed the container dimensions. This may crop the top and bottom of the image if the scaled image height is greater than the container height, or crop the left and right of the image if the scaled image width is greater than the container width. This is similar to \"Zoom Mode\" on a widescreen TV when playing a 4:3 video.",
            "Pad the gaps between image and image frame with a blurred copy of the same image."
          ],
          "description": "Optional. Settings for displaying the image. Applies to every image in items."
        }
      }
    },
    "GoogleCloudDialogflowV2ConversationEvent": {
      "type": "object",
      "properties": {
        "conversation": {
          "type": "string",
          "description": "The unique identifier of the conversation this notification refers to. Format: `projects//conversations/`."
        },
        "newMessagePayload": {
          "description": "Payload of NEW_MESSAGE event.",
          "$ref": "GoogleCloudDialogflowV2Message"
        },
        "errorStatus": {
          "$ref": "GoogleRpcStatus",
          "description": "More detailed information about an error. Only set for type UNRECOVERABLE_ERROR_IN_PHONE_CALL."
        },
        "type": {
          "type": "string",
          "description": "The type of the event that this notification refers to.",
          "enumDescriptions": [
            "Type not set.",
            "A new conversation has been opened. This is fired when a telephone call is answered, or a conversation is created via the API.",
            "An existing conversation has closed. This is fired when a telephone call is terminated, or a conversation is closed via the API.",
            "An existing conversation has received notification from Dialogflow that human intervention is required.",
            "An existing conversation has received a new message, either from API or telephony. It is configured in ConversationProfile.new_message_event_notification_config",
            "Unrecoverable error during a telephone call. In general non-recoverable errors only occur if something was misconfigured in the ConversationProfile corresponding to the call. After a non-recoverable error, Dialogflow may stop responding. We don't fire this event: * in an API call because we can directly return the error, or, * when we can recover from an error."
          ],
          "enum": [
            "TYPE_UNSPECIFIED",
            "CONVERSATION_STARTED",
            "CONVERSATION_FINISHED",
            "HUMAN_INTERVENTION_NEEDED",
            "NEW_MESSAGE",
            "UNRECOVERABLE_ERROR"
          ]
        }
      },
      "description": "Represents a notification sent to Pub/Sub subscribers for conversation lifecycle events.",
      "id": "GoogleCloudDialogflowV2ConversationEvent"
    },
    "GoogleCloudDialogflowV2IntentMessageSuggestions": {
      "id": "GoogleCloudDialogflowV2IntentMessageSuggestions",
      "description": "The collection of suggestions.",
      "properties": {
        "suggestions": {
          "items": {
            "$ref": "GoogleCloudDialogflowV2IntentMessageSuggestion"
          },
          "description": "Required. The list of suggested replies.",
          "type": "array"
        }
      },
      "type": "object"
    },
    "GoogleCloudDialogflowV2IntentMessageQuickReplies": {
      "type": "object",
      "id": "GoogleCloudDialogflowV2IntentMessageQuickReplies",
      "description": "The quick replies response message.",
      "properties": {
        "quickReplies": {
          "type": "array",
          "items": {
            "type": "string"
          },
          "description": "Optional. The collection of quick replies."
        },
        "title": {
          "type": "string",
          "description": "Optional. The title of the collection of quick replies."
        }
      }
    },
    "GoogleCloudDialogflowV2beta1Intent": {
      "properties": {
        "action": {
          "type": "string",
          "description": "Optional. The name of the action associated with the intent. Note: The action name must not contain whitespaces."
        },
        "messages": {
          "items": {
            "$ref": "GoogleCloudDialogflowV2beta1IntentMessage"
          },
          "description": "Optional. The collection of rich messages corresponding to the `Response` field in the Dialogflow console.",
          "type": "array"
        },
        "trainingPhrases": {
          "type": "array",
          "description": "Optional. The collection of examples that the agent is trained on.",
          "items": {
            "$ref": "GoogleCloudDialogflowV2beta1IntentTrainingPhrase"
          }
        },
        "defaultResponsePlatforms": {
          "type": "array",
          "items": {
            "type": "string",
            "enum": [
              "PLATFORM_UNSPECIFIED",
              "FACEBOOK",
              "SLACK",
              "TELEGRAM",
              "KIK",
              "SKYPE",
              "LINE",
              "VIBER",
              "ACTIONS_ON_GOOGLE",
              "TELEPHONY",
              "GOOGLE_HANGOUTS"
            ],
            "enumDescriptions": [
              "Not specified.",
              "Facebook.",
              "Slack.",
              "Telegram.",
              "Kik.",
              "Skype.",
              "Line.",
              "Viber.",
              "Google Assistant See [Dialogflow webhook format](https://developers.google.com/assistant/actions/build/json/dialogflow-webhook-json)",
              "Telephony Gateway.",
              "Google Hangouts."
            ]
          },
          "description": "Optional. The list of platforms for which the first responses will be copied from the messages in PLATFORM_UNSPECIFIED (i.e. default platform).",
          "enumDescriptions": [
            "Not specified.",
            "Facebook.",
            "Slack.",
            "Telegram.",
            "Kik.",
            "Skype.",
            "Line.",
            "Viber.",
            "Google Assistant See [Dialogflow webhook format](https://developers.google.com/assistant/actions/build/json/dialogflow-webhook-json)",
            "Telephony Gateway.",
            "Google Hangouts."
          ]
        },
        "inputContextNames": {
          "type": "array",
          "items": {
            "type": "string"
          },
          "description": "Optional. The list of context names required for this intent to be triggered. Format: `projects//agent/sessions/-/contexts/`."
        },
        "displayName": {
          "type": "string",
          "description": "Required. The name of this intent."
        },
        "resetContexts": {
          "type": "boolean",
          "description": "Optional. Indicates whether to delete all contexts in the current session when this intent is matched."
        },
        "parentFollowupIntentName": {
          "description": "Optional. The unique identifier of the parent intent in the chain of followup intents. You can set this field when creating an intent, for example with CreateIntent or BatchUpdateIntents, in order to make this intent a followup intent. It identifies the parent followup intent. Format: `projects//agent/intents/`.",
          "type": "string"
        },
        "mlDisabled": {
          "description": "Optional. Indicates whether Machine Learning is disabled for the intent. Note: If `ml_disabled` setting is set to true, then this intent is not taken into account during inference in `ML ONLY` match mode. Also, auto-markup in the UI is turned off.",
          "type": "boolean"
        },
        "events": {
          "items": {
            "type": "string"
          },
          "type": "array",
          "description": "Optional. The collection of event names that trigger the intent. If the collection of input contexts is not empty, all of the contexts must be present in the active user session for an event to trigger this intent. Event names are limited to 150 characters."
        },
        "webhookState": {
          "enum": [
            "WEBHOOK_STATE_UNSPECIFIED",
            "WEBHOOK_STATE_ENABLED",
            "WEBHOOK_STATE_ENABLED_FOR_SLOT_FILLING"
          ],
          "description": "Optional. Indicates whether webhooks are enabled for the intent.",
          "enumDescriptions": [
            "Webhook is disabled in the agent and in the intent.",
            "Webhook is enabled in the agent and in the intent.",
            "Webhook is enabled in the agent and in the intent. Also, each slot filling prompt is forwarded to the webhook."
          ],
          "type": "string"
        },
        "parameters": {
          "type": "array",
          "description": "Optional. The collection of parameters associated with the intent.",
          "items": {
            "$ref": "GoogleCloudDialogflowV2beta1IntentParameter"
          }
        },
        "name": {
          "description": "Optional. The unique identifier of this intent. Required for Intents.UpdateIntent and Intents.BatchUpdateIntents methods. Format: `projects//agent/intents/`.",
          "type": "string"
        },
        "isFallback": {
          "description": "Optional. Indicates whether this is a fallback intent.",
          "type": "boolean"
        },
        "priority": {
          "type": "integer",
          "description": "Optional. The priority of this intent. Higher numbers represent higher priorities. - If the supplied value is unspecified or 0, the service translates the value to 500,000, which corresponds to the `Normal` priority in the console. - If the supplied value is negative, the intent is ignored in runtime detect intent requests.",
          "format": "int32"
        },
        "endInteraction": {
          "description": "Optional. Indicates that this intent ends an interaction. Some integrations (e.g., Actions on Google or Dialogflow phone gateway) use this information to close interaction with an end user. Default is false.",
          "type": "boolean"
        },
        "rootFollowupIntentName": {
          "description": "Output only. The unique identifier of the root intent in the chain of followup intents. It identifies the correct followup intents chain for this intent. Format: `projects//agent/intents/`.",
          "type": "string",
          "readOnly": true
        },
        "followupIntentInfo": {
          "description": "Output only. Information about all followup intents that have this intent as a direct or indirect parent. We populate this field only in the output.",
          "readOnly": true,
          "items": {
            "$ref": "GoogleCloudDialogflowV2beta1IntentFollowupIntentInfo"
          },
          "type": "array"
        },
        "mlEnabled": {
          "type": "boolean",
          "description": "Optional. Indicates whether Machine Learning is enabled for the intent. Note: If `ml_enabled` setting is set to false, then this intent is not taken into account during inference in `ML ONLY` match mode. Also, auto-markup in the UI is turned off. DEPRECATED! Please use `ml_disabled` field instead. NOTE: If both `ml_enabled` and `ml_disabled` are either not set or false, then the default value is determined as follows: - Before April 15th, 2018 the default is: ml_enabled = false / ml_disabled = true. - After April 15th, 2018 the default is: ml_enabled = true / ml_disabled = false."
        },
        "outputContexts": {
          "description": "Optional. The collection of contexts that are activated when the intent is matched. Context messages in this collection should not set the parameters field. Setting the `lifespan_count` to 0 will reset the context when the intent is matched. Format: `projects//agent/sessions/-/contexts/`.",
          "type": "array",
          "items": {
            "$ref": "GoogleCloudDialogflowV2beta1Context"
          }
        }
      },
      "type": "object",
      "description": "An intent categorizes an end-user's intention for one conversation turn. For each agent, you define many intents, where your combined intents can handle a complete conversation. When an end-user writes or says something, referred to as an end-user expression or end-user input, Dialogflow matches the end-user input to the best intent in your agent. Matching an intent is also known as intent classification. For more information, see the [intent guide](https://cloud.google.com/dialogflow/docs/intents-overview).",
      "id": "GoogleCloudDialogflowV2beta1Intent"
    },
    "GoogleCloudDialogflowCxV3beta1ResponseMessageHumanAgentHandoff": {
      "properties": {
        "metadata": {
          "description": "Custom metadata for your handoff procedure. Dialogflow doesn't impose any structure on this.",
          "type": "object",
          "additionalProperties": {
            "type": "any",
            "description": "Properties of the object."
          }
        }
      },
      "id": "GoogleCloudDialogflowCxV3beta1ResponseMessageHumanAgentHandoff",
      "type": "object",
      "description": "Indicates that the conversation should be handed off to a human agent. Dialogflow only uses this to determine which conversations were handed off to a human agent for measurement purposes. What else to do with this signal is up to you and your handoff procedures. You may set this, for example: * In the entry_fulfillment of a Page if entering the page indicates something went extremely wrong in the conversation. * In a webhook response when you determine that the customer issue can only be handled by a human."
    },
    "GoogleCloudDialogflowV2beta1IntentTrainingPhrasePart": {
      "id": "GoogleCloudDialogflowV2beta1IntentTrainingPhrasePart",
      "type": "object",
      "properties": {
        "text": {
          "type": "string",
          "description": "Required. The text for this part."
        },
        "entityType": {
          "type": "string",
          "description": "Optional. The entity type name prefixed with `@`. This field is required for annotated parts of the training phrase."
        },
        "userDefined": {
          "description": "Optional. Indicates whether the text was manually annotated. This field is set to true when the Dialogflow Console is used to manually annotate the part. When creating an annotated part with the API, you must set this to true.",
          "type": "boolean"
        },
        "alias": {
          "type": "string",
          "description": "Optional. The parameter name for the value extracted from the annotated part of the example. This field is required for annotated parts of the training phrase."
        }
      },
      "description": "Represents a part of a training phrase."
    },
    "GoogleRpcStatus": {
      "properties": {
        "message": {
          "description": "A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client.",
          "type": "string"
        },
        "code": {
          "description": "The status code, which should be an enum value of google.rpc.Code.",
          "format": "int32",
          "type": "integer"
        },
        "details": {
          "description": "A list of messages that carry the error details. There is a common set of message types for APIs to use.",
          "type": "array",
          "items": {
            "type": "object",
            "additionalProperties": {
              "type": "any",
              "description": "Properties of the object. Contains field @type with type URL."
            }
          }
        }
      },
      "description": "The `Status` type defines a logical error model that is suitable for different programming environments, including REST APIs and RPC APIs. It is used by [gRPC](https://github.com/grpc). Each `Status` message contains three pieces of data: error code, error message, and error details. You can find out more about this error model and how to work with it in the [API Design Guide](https://cloud.google.com/apis/design/errors).",
      "type": "object",
      "id": "GoogleRpcStatus"
    },
    "GoogleCloudDialogflowV2beta1IntentMessageRbmCardContent": {
      "description": "Rich Business Messaging (RBM) Card content",
      "id": "GoogleCloudDialogflowV2beta1IntentMessageRbmCardContent",
      "type": "object",
      "properties": {
        "suggestions": {
          "type": "array",
          "items": {
            "$ref": "GoogleCloudDialogflowV2beta1IntentMessageRbmSuggestion"
          },
          "description": "Optional. List of suggestions to include in the card."
        },
        "title": {
          "type": "string",
          "description": "Optional. Title of the card (at most 200 bytes). At least one of the title, description or media must be set."
        },
        "description": {
          "description": "Optional. Description of the card (at most 2000 bytes). At least one of the title, description or media must be set.",
          "type": "string"
        },
        "media": {
          "$ref": "GoogleCloudDialogflowV2beta1IntentMessageRbmCardContentRbmMedia",
          "description": "Optional. However at least one of the title, description or media must be set. Media (image, GIF or a video) to include in the card."
        }
      }
    },
    "GoogleCloudDialogflowCxV3beta1WebhookRequestFulfillmentInfo": {
      "type": "object",
      "id": "GoogleCloudDialogflowCxV3beta1WebhookRequestFulfillmentInfo",
      "description": "Represents fulfillment information communicated to the webhook.",
      "properties": {
        "tag": {
          "description": "Always present. The tag used to identify which fulfillment is being called.",
          "type": "string"
        }
      }
    },
    "GoogleCloudDialogflowV2beta1IntentMessageCarouselSelect": {
      "properties": {
        "items": {
          "description": "Required. Carousel items.",
          "type": "array",
          "items": {
            "$ref": "GoogleCloudDialogflowV2beta1IntentMessageCarouselSelectItem"
          }
        }
      },
      "description": "The card for presenting a carousel of options to select from.",
      "type": "object",
      "id": "GoogleCloudDialogflowV2beta1IntentMessageCarouselSelect"
    },
    "GoogleCloudDialogflowV2beta1IntentMessageBrowseCarouselCardBrowseCarouselCardItem": {
      "description": "Browsing carousel tile",
      "properties": {
        "title": {
          "type": "string",
          "description": "Required. Title of the carousel item. Maximum of two lines of text."
        },
        "footer": {
          "description": "Optional. Text that appears at the bottom of the Browse Carousel Card. Maximum of one line of text.",
          "type": "string"
        },
        "openUriAction": {
          "description": "Required. Action to present to the user.",
          "$ref": "GoogleCloudDialogflowV2beta1IntentMessageBrowseCarouselCardBrowseCarouselCardItemOpenUrlAction"
        },
        "description": {
          "type": "string",
          "description": "Optional. Description of the carousel item. Maximum of four lines of text."
        },
        "image": {
          "$ref": "GoogleCloudDialogflowV2beta1IntentMessageImage",
          "description": "Optional. Hero image for the carousel item."
        }
      },
      "id": "GoogleCloudDialogflowV2beta1IntentMessageBrowseCarouselCardBrowseCarouselCardItem",
      "type": "object"
    },
    "GoogleCloudDialogflowV2IntentMessageTableCardRow": {
      "description": "Row of TableCard.",
      "properties": {
        "cells": {
          "description": "Optional. List of cells that make up this row.",
          "items": {
            "$ref": "GoogleCloudDialogflowV2IntentMessageTableCardCell"
          },
          "type": "array"
        },
        "dividerAfter": {
          "description": "Optional. Whether to add a visual divider after this row.",
          "type": "boolean"
        }
      },
      "type": "object",
      "id": "GoogleCloudDialogflowV2IntentMessageTableCardRow"
    },
    "GoogleCloudDialogflowCxV3beta1CreateVersionOperationMetadata": {
      "type": "object",
      "properties": {
        "version": {
          "type": "string",
          "description": "Name of the created version. Format: `projects//locations//agents//flows//versions/`."
        }
      },
      "id": "GoogleCloudDialogflowCxV3beta1CreateVersionOperationMetadata",
      "description": "Metadata associated with the long running operation for Versions.CreateVersion."
    },
    "GoogleCloudDialogflowCxV3beta1ResponseMessage": {
      "type": "object",
      "description": "Represents a response message that can be returned by a conversational agent. Response messages are also used for output audio synthesis. The approach is as follows: * If at least one OutputAudioText response is present, then all OutputAudioText responses are linearly concatenated, and the result is used for output audio synthesis. * If the OutputAudioText responses are a mixture of text and SSML, then the concatenated result is treated as SSML; otherwise, the result is treated as either text or SSML as appropriate. The agent designer should ideally use either text or SSML consistently throughout the bot design. * Otherwise, all Text responses are linearly concatenated, and the result is used for output audio synthesis. This approach allows for more sophisticated user experience scenarios, where the text displayed to the user may differ from what is heard.",
      "properties": {
        "conversationSuccess": {
          "$ref": "GoogleCloudDialogflowCxV3beta1ResponseMessageConversationSuccess",
          "description": "Indicates that the conversation succeeded."
        },
        "payload": {
          "type": "object",
          "additionalProperties": {
            "description": "Properties of the object.",
            "type": "any"
          },
          "description": "Returns a response containing a custom, platform-specific payload."
        },
        "text": {
          "$ref": "GoogleCloudDialogflowCxV3beta1ResponseMessageText",
          "description": "Returns a text response."
        },
        "playAudio": {
          "description": "Signal that the client should play an audio clip hosted at a client-specific URI. Dialogflow uses this to construct mixed_audio. However, Dialogflow itself does not try to read or process the URI in any way.",
          "$ref": "GoogleCloudDialogflowCxV3beta1ResponseMessagePlayAudio"
        },
        "endInteraction": {
          "$ref": "GoogleCloudDialogflowCxV3beta1ResponseMessageEndInteraction",
          "readOnly": true,
          "description": "Output only. A signal that indicates the interaction with the Dialogflow agent has ended. This message is generated by Dialogflow only when the conversation reaches `END_SESSION` or `END_PAGE` page. It is not supposed to be defined by the user. It's guaranteed that there is at most one such message in each response."
        },
        "outputAudioText": {
          "description": "A text or ssml response that is preferentially used for TTS output audio synthesis, as described in the comment on the ResponseMessage message.",
          "$ref": "GoogleCloudDialogflowCxV3beta1ResponseMessageOutputAudioText"
        },
        "humanAgentHandoff": {
          "$ref": "GoogleCloudDialogflowCxV3beta1ResponseMessageHumanAgentHandoff",
          "description": "Hands off conversation to a human agent."
        },
        "mixedAudio": {
          "description": "Output only. An audio response message composed of both the synthesized Dialogflow agent responses and responses defined via play_audio. This message is generated by Dialogflow only and not supposed to be defined by the user.",
          "readOnly": true,
          "$ref": "GoogleCloudDialogflowCxV3beta1ResponseMessageMixedAudio"
        },
        "liveAgentHandoff": {
          "description": "Hands off conversation to a human agent.",
          "$ref": "GoogleCloudDialogflowCxV3beta1ResponseMessageLiveAgentHandoff"
        }
      },
      "id": "GoogleCloudDialogflowCxV3beta1ResponseMessage"
    },
    "GoogleCloudDialogflowCxV3beta1WebhookRequestIntentInfo": {
      "type": "object",
      "properties": {
        "lastMatchedIntent": {
          "description": "Always present. The unique identifier of the last matched intent. Format: `projects//locations//agents//intents/`.",
          "type": "string"
        },
        "parameters": {
          "type": "object",
          "description": "Parameters identified as a result of intent matching. This is a map of the name of the identified parameter to the value of the parameter identified from the user's utterance. All parameters defined in the matched intent that are identified will be surfaced here.",
          "additionalProperties": {
            "$ref": "GoogleCloudDialogflowCxV3beta1WebhookRequestIntentInfoIntentParameterValue"
          }
        }
      },
      "description": "Represents intent information communicated to the webhook.",
      "id": "GoogleCloudDialogflowCxV3beta1WebhookRequestIntentInfo"
    },
    "GoogleCloudDialogflowV2Sentiment": {
      "type": "object",
      "properties": {
        "magnitude": {
          "description": "A non-negative number in the [0, +inf) range, which represents the absolute magnitude of sentiment, regardless of score (positive or negative).",
          "type": "number",
          "format": "float"
        },
        "score": {
          "description": "Sentiment score between -1.0 (negative sentiment) and 1.0 (positive sentiment).",
          "format": "float",
          "type": "number"
        }
      },
      "description": "The sentiment, such as positive/negative feeling or association, for a unit of analysis, such as the query text.",
      "id": "GoogleCloudDialogflowV2Sentiment"
    },
    "GoogleCloudDialogflowV2ExportAgentResponse": {
      "type": "object",
      "properties": {
        "agentContent": {
          "format": "byte",
          "description": "Zip compressed raw byte content for agent.",
          "type": "string"
        },
        "agentUri": {
          "type": "string",
          "description": "The URI to a file containing the exported agent. This field is populated only if `agent_uri` is specified in `ExportAgentRequest`."
        }
      },
      "id": "GoogleCloudDialogflowV2ExportAgentResponse",
      "description": "The response message for Agents.ExportAgent."
    },
    "GoogleCloudDialogflowV2SessionEntityType": {
      "description": "A session represents a conversation between a Dialogflow agent and an end-user. You can create special entities, called session entities, during a session. Session entities can extend or replace custom entity types and only exist during the session that they were created for. All session data, including session entities, is stored by Dialogflow for 20 minutes. For more information, see the [session entity guide](https://cloud.google.com/dialogflow/docs/entities-session).",
      "type": "object",
      "id": "GoogleCloudDialogflowV2SessionEntityType",
      "properties": {
        "entities": {
          "description": "Required. The collection of entities associated with this session entity type.",
          "type": "array",
          "items": {
            "$ref": "GoogleCloudDialogflowV2EntityTypeEntity"
          }
        },
        "entityOverrideMode": {
          "enumDescriptions": [
            "Not specified. This value should be never used.",
            "The collection of session entities overrides the collection of entities in the corresponding custom entity type.",
            "The collection of session entities extends the collection of entities in the corresponding custom entity type. Note: Even in this override mode calls to `ListSessionEntityTypes`, `GetSessionEntityType`, `CreateSessionEntityType` and `UpdateSessionEntityType` only return the additional entities added in this session entity type. If you want to get the supplemented list, please call EntityTypes.GetEntityType on the custom entity type and merge."
          ],
          "description": "Required. Indicates whether the additional data should override or supplement the custom entity type definition.",
          "type": "string",
          "enum": [
            "ENTITY_OVERRIDE_MODE_UNSPECIFIED",
            "ENTITY_OVERRIDE_MODE_OVERRIDE",
            "ENTITY_OVERRIDE_MODE_SUPPLEMENT"
          ]
        },
        "name": {
          "type": "string",
          "description": "Required. The unique identifier of this session entity type. Format: `projects//agent/sessions//entityTypes/`, or `projects//agent/environments//users//sessions//entityTypes/`. If `Environment ID` is not specified, we assume default 'draft' environment. If `User ID` is not specified, we assume default '-' user. `` must be the display name of an existing entity type in the same agent that will be overridden or supplemented."
        }
      }
    },
    "GoogleCloudDialogflowV2beta1IntentMessageMediaContentResponseMediaObject": {
      "description": "Response media object for media content card.",
      "properties": {
        "largeImage": {
          "$ref": "GoogleCloudDialogflowV2beta1IntentMessageImage",
          "description": "Optional. Image to display above media content."
        },
        "name": {
          "type": "string",
          "description": "Required. Name of media card."
        },
        "description": {
          "description": "Optional. Description of media card.",
          "type": "string"
        },
        "contentUrl": {
          "description": "Required. Url where the media is stored.",
          "type": "string"
        },
        "icon": {
          "description": "Optional. Icon to display above media content.",
          "$ref": "GoogleCloudDialogflowV2beta1IntentMessageImage"
        }
      },
      "type": "object",
      "id": "GoogleCloudDialogflowV2beta1IntentMessageMediaContentResponseMediaObject"
    },
    "GoogleCloudDialogflowV2beta1IntentMessageSimpleResponses": {
      "description": "The collection of simple response candidates. This message in `QueryResult.fulfillment_messages` and `WebhookResponse.fulfillment_messages` should contain only one `SimpleResponse`.",
      "properties": {
        "simpleResponses": {
          "type": "array",
          "items": {
            "$ref": "GoogleCloudDialogflowV2beta1IntentMessageSimpleResponse"
          },
          "description": "Required. The list of simple responses."
        }
      },
      "id": "GoogleCloudDialogflowV2beta1IntentMessageSimpleResponses",
      "type": "object"
    },
    "GoogleCloudDialogflowV2beta1KnowledgeAnswersAnswer": {
      "description": "An answer from Knowledge Connector.",
      "id": "GoogleCloudDialogflowV2beta1KnowledgeAnswersAnswer",
      "properties": {
        "faqQuestion": {
          "description": "The corresponding FAQ question if the answer was extracted from a FAQ Document, empty otherwise.",
          "type": "string"
        },
        "source": {
          "type": "string",
          "description": "Indicates which Knowledge Document this answer was extracted from. Format: `projects//knowledgeBases//documents/`."
        },
        "matchConfidence": {
          "format": "float",
          "type": "number",
          "description": "The system's confidence score that this Knowledge answer is a good match for this conversational query. The range is from 0.0 (completely uncertain) to 1.0 (completely certain). Note: The confidence score is likely to vary somewhat (possibly even for identical requests), as the underlying model is under constant improvement. It may be deprecated in the future. We recommend using `match_confidence_level` which should be generally more stable."
        },
        "matchConfidenceLevel": {
          "type": "string",
          "enumDescriptions": [
            "Not specified.",
            "Indicates that the confidence is low.",
            "Indicates our confidence is medium.",
            "Indicates our confidence is high."
          ],
          "enum": [
            "MATCH_CONFIDENCE_LEVEL_UNSPECIFIED",
            "LOW",
            "MEDIUM",
            "HIGH"
          ],
          "description": "The system's confidence level that this knowledge answer is a good match for this conversational query. NOTE: The confidence level for a given `` pair may change without notice, as it depends on models that are constantly being improved. However, it will change less frequently than the confidence score below, and should be preferred for referencing the quality of an answer."
        },
        "answer": {
          "description": "The piece of text from the `source` knowledge base document that answers this conversational query.",
          "type": "string"
        }
      },
      "type": "object"
    },
    "GoogleCloudDialogflowCxV3beta1ResponseMessagePlayAudio": {
      "id": "GoogleCloudDialogflowCxV3beta1ResponseMessagePlayAudio",
      "type": "object",
      "properties": {
        "audioUri": {
          "type": "string",
          "description": "Required. URI of the audio clip. Dialogflow does not impose any validation on this value. It is specific to the client that reads it."
        },
        "allowPlaybackInterruption": {
          "readOnly": true,
          "description": "Output only. Whether the playback of this message can be interrupted by the end user's speech and the client can then starts the next Dialogflow request.",
          "type": "boolean"
        }
      },
      "description": "Specifies an audio clip to be played by the client as part of the response."
    },
    "GoogleCloudDialogflowV2beta1BatchUpdateIntentsResponse": {
      "properties": {
        "intents": {
          "type": "array",
          "description": "The collection of updated or created intents.",
          "items": {
            "$ref": "GoogleCloudDialogflowV2beta1Intent"
          }
        }
      },
      "id": "GoogleCloudDialogflowV2beta1BatchUpdateIntentsResponse",
      "type": "object",
      "description": "The response message for Intents.BatchUpdateIntents."
    },
    "GoogleCloudDialogflowV2IntentMessageLinkOutSuggestion": {
      "type": "object",
      "id": "GoogleCloudDialogflowV2IntentMessageLinkOutSuggestion",
      "properties": {
        "destinationName": {
          "description": "Required. The name of the app or site this chip is linking to.",
          "type": "string"
        },
        "uri": {
          "description": "Required. The URI of the app or site to open when the user taps the suggestion chip.",
          "type": "string"
        }
      },
      "description": "The suggestion chip message that allows the user to jump out to the app or website associated with this agent."
    },
    "GoogleCloudDialogflowV2BatchUpdateEntityTypesResponse": {
      "type": "object",
      "properties": {
        "entityTypes": {
          "description": "The collection of updated or created entity types.",
          "type": "array",
          "items": {
            "$ref": "GoogleCloudDialogflowV2EntityType"
          }
        }
      },
      "description": "The response message for EntityTypes.BatchUpdateEntityTypes.",
      "id": "GoogleCloudDialogflowV2BatchUpdateEntityTypesResponse"
    },
    "GoogleCloudDialogflowV2IntentMessageMediaContent": {
      "id": "GoogleCloudDialogflowV2IntentMessageMediaContent",
      "type": "object",
      "description": "The media content card for Actions on Google.",
      "properties": {
        "mediaObjects": {
          "items": {
            "$ref": "GoogleCloudDialogflowV2IntentMessageMediaContentResponseMediaObject"
          },
          "type": "array",
          "description": "Required. List of media objects."
        },
        "mediaType": {
          "enum": [
            "RESPONSE_MEDIA_TYPE_UNSPECIFIED",
            "AUDIO"
          ],
          "type": "string",
          "description": "Optional. What type of media is the content (ie \"audio\").",
          "enumDescriptions": [
            "Unspecified.",
            "Response media type is audio."
          ]
        }
      }
    },
    "GoogleCloudDialogflowV2MessageAnnotation": {
      "properties": {
        "parts": {
          "type": "array",
          "description": "The collection of annotated message parts ordered by their position in the message. You can recover the annotated message by concatenating [AnnotatedMessagePart.text].",
          "items": {
            "$ref": "GoogleCloudDialogflowV2AnnotatedMessagePart"
          }
        },
        "containEntities": {
          "description": "Indicates whether the text message contains entities.",
          "type": "boolean"
        }
      },
      "description": "Represents the result of annotation for the message.",
      "type": "object",
      "id": "GoogleCloudDialogflowV2MessageAnnotation"
    },
    "GoogleCloudDialogflowV2IntentMessageSuggestion": {
      "type": "object",
      "properties": {
        "title": {
          "type": "string",
          "description": "Required. The text shown the in the suggestion chip."
        }
      },
      "id": "GoogleCloudDialogflowV2IntentMessageSuggestion",
      "description": "The suggestion chip message that the user can tap to quickly post a reply to the conversation."
    },
    "GoogleCloudDialogflowV2IntentParameter": {
      "id": "GoogleCloudDialogflowV2IntentParameter",
      "properties": {
        "value": {
          "description": "Optional. The definition of the parameter value. It can be: - a constant string, - a parameter value defined as `$parameter_name`, - an original parameter value defined as `$parameter_name.original`, - a parameter value from some context defined as `#context_name.parameter_name`.",
          "type": "string"
        },
        "prompts": {
          "type": "array",
          "description": "Optional. The collection of prompts that the agent can present to the user in order to collect a value for the parameter.",
          "items": {
            "type": "string"
          }
        },
        "displayName": {
          "type": "string",
          "description": "Required. The name of the parameter."
        },
        "mandatory": {
          "description": "Optional. Indicates whether the parameter is required. That is, whether the intent cannot be completed without collecting the parameter value.",
          "type": "boolean"
        },
        "entityTypeDisplayName": {
          "type": "string",
          "description": "Optional. The name of the entity type, prefixed with `@`, that describes values of the parameter. If the parameter is required, this must be provided."
        },
        "name": {
          "type": "string",
          "description": "The unique identifier of this parameter."
        },
        "isList": {
          "description": "Optional. Indicates whether the parameter represents a list of values.",
          "type": "boolean"
        },
        "defaultValue": {
          "type": "string",
          "description": "Optional. The default value to use when the `value` yields an empty result. Default values can be extracted from contexts by using the following syntax: `#context_name.parameter_name`."
        }
      },
      "description": "Represents intent parameters.",
      "type": "object"
    },
    "GoogleCloudDialogflowV2Message": {
      "type": "object",
      "properties": {
        "languageCode": {
          "description": "Optional. The message language. This should be a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag. Example: \"en-US\".",
          "type": "string"
        },
        "createTime": {
          "type": "string",
          "format": "google-datetime",
          "description": "Output only. The time when the message was created.",
          "readOnly": true
        },
        "name": {
          "description": "The unique identifier of the message. Format: `projects//conversations//messages/`.",
          "type": "string"
        },
        "participantRole": {
          "description": "Output only. The role of the participant.",
          "enumDescriptions": [
            "Participant role not set.",
            "Participant is a human agent.",
            "Participant is an automated agent, such as a Dialogflow agent.",
            "Participant is an end user that has called or chatted with Dialogflow services."
          ],
          "type": "string",
          "enum": [
            "ROLE_UNSPECIFIED",
            "HUMAN_AGENT",
            "AUTOMATED_AGENT",
            "END_USER"
          ],
          "readOnly": true
        },
        "participant": {
          "readOnly": true,
          "description": "Output only. The participant that sends this message.",
          "type": "string"
        },
        "messageAnnotation": {
          "readOnly": true,
          "description": "Output only. The annotation for the message.",
          "$ref": "GoogleCloudDialogflowV2MessageAnnotation"
        },
        "content": {
          "description": "Required. The message content.",
          "type": "string"
        }
      },
      "description": "Represents a message posted into a conversation.",
      "id": "GoogleCloudDialogflowV2Message"
    },
    "GoogleCloudDialogflowV2IntentMessageTableCardCell": {
      "type": "object",
      "description": "Cell of TableCardRow.",
      "id": "GoogleCloudDialogflowV2IntentMessageTableCardCell",
      "properties": {
        "text": {
          "description": "Required. Text in this cell.",
          "type": "string"
        }
      }
    },
    "GoogleCloudDialogflowV2AnnotatedMessagePart": {
      "description": "Represents a part of a message possibly annotated with an entity. The part can be an entity or purely a part of the message between two entities or message start/end.",
      "type": "object",
      "properties": {
        "text": {
          "type": "string",
          "description": "A part of a message possibly annotated with an entity."
        },
        "formattedValue": {
          "type": "any",
          "description": "The [Dialogflow system entity formatted value ](https://cloud.google.com/dialogflow/docs/reference/system-entities) of this message part. For example for a system entity of type `@sys.unit-currency`, this may contain: { \"amount\": 5, \"currency\": \"USD\" } "
        },
        "entityType": {
          "type": "string",
          "description": "The [Dialogflow system entity type](https://cloud.google.com/dialogflow/docs/reference/system-entities) of this message part. If this is empty, Dialogflow could not annotate the phrase part with a system entity."
        }
      },
      "id": "GoogleCloudDialogflowV2AnnotatedMessagePart"
    },
    "GoogleLongrunningOperation": {
      "description": "This resource represents a long-running operation that is the result of a network API call.",
      "type": "object",
      "properties": {
        "done": {
          "description": "If the value is `false`, it means the operation is still in progress. If `true`, the operation is completed, and either `error` or `response` is available.",
          "type": "boolean"
        },
        "error": {
          "$ref": "GoogleRpcStatus",
          "description": "The error result of the operation in case of failure or cancellation."
        },
        "metadata": {
          "type": "object",
          "additionalProperties": {
            "type": "any",
            "description": "Properties of the object. Contains field @type with type URL."
          },
          "description": "Service-specific metadata associated with the operation. It typically contains progress information and common metadata such as create time. Some services might not provide such metadata. Any method that returns a long-running operation should document the metadata type, if any."
        },
        "response": {
          "additionalProperties": {
            "type": "any",
            "description": "Properties of the object. Contains field @type with type URL."
          },
          "type": "object",
          "description": "The normal response of the operation in case of success. If the original method returns no data on success, such as `Delete`, the response is `google.protobuf.Empty`. If the original method is standard `Get`/`Create`/`Update`, the response should be the resource. For other methods, the response should have the type `XxxResponse`, where `Xxx` is the original method name. For example, if the original method name is `TakeSnapshot()`, the inferred response type is `TakeSnapshotResponse`."
        },
        "name": {
          "description": "The server-assigned name, which is only unique within the same service that originally returns it. If you use the default HTTP mapping, the `name` should be a resource name ending with `operations/{unique_id}`.",
          "type": "string"
        }
      },
      "id": "GoogleLongrunningOperation"
    },
    "GoogleCloudDialogflowV2beta1KnowledgeOperationMetadata": {
      "properties": {
        "state": {
          "type": "string",
          "enum": [
            "STATE_UNSPECIFIED",
            "PENDING",
            "RUNNING",
            "DONE"
          ],
          "readOnly": true,
          "description": "Required. Output only. The current state of this operation.",
          "enumDescriptions": [
            "State unspecified.",
            "The operation has been created.",
            "The operation is currently running.",
            "The operation is done, either cancelled or completed."
          ]
        }
      },
      "id": "GoogleCloudDialogflowV2beta1KnowledgeOperationMetadata",
      "type": "object",
      "description": "Metadata in google::longrunning::Operation for Knowledge operations."
    },
    "GoogleCloudDialogflowCxV3beta1WebhookResponseFulfillmentResponse": {
      "properties": {
        "mergeBehavior": {
          "enum": [
            "MERGE_BEHAVIOR_UNSPECIFIED",
            "APPEND",
            "REPLACE"
          ],
          "description": "Merge behavior for `messages`.",
          "enumDescriptions": [
            "Not specified. `APPEND` will be used.",
            "`messages` will be appended to the list of messages waiting to be sent to the user.",
            "`messages` will replace the list of messages waiting to be sent to the user."
          ],
          "type": "string"
        },
        "messages": {
          "description": "The list of rich message responses to present to the user.",
          "items": {
            "$ref": "GoogleCloudDialogflowCxV3beta1ResponseMessage"
          },
          "type": "array"
        }
      },
      "type": "object",
      "id": "GoogleCloudDialogflowCxV3beta1WebhookResponseFulfillmentResponse",
      "description": "Represents a fulfillment response to the user."
    },
    "GoogleCloudDialogflowV2EventInput": {
      "id": "GoogleCloudDialogflowV2EventInput",
      "properties": {
        "parameters": {
          "additionalProperties": {
            "description": "Properties of the object.",
            "type": "any"
          },
          "type": "object",
          "description": "The collection of parameters associated with the event. Depending on your protocol or client library language, this is a map, associative array, symbol table, dictionary, or JSON object composed of a collection of (MapKey, MapValue) pairs: - MapKey type: string - MapKey value: parameter name - MapValue type: - If parameter's entity type is a composite entity: map - Else: string or number, depending on parameter value type - MapValue value: - If parameter's entity type is a composite entity: map from composite entity property names to property values - Else: parameter value"
        },
        "name": {
          "description": "Required. The unique identifier of the event.",
          "type": "string"
        },
        "languageCode": {
          "type": "string",
          "description": "Required. The language of this query. See [Language Support](https://cloud.google.com/dialogflow/docs/reference/language) for a list of the currently supported language codes. Note that queries in the same session do not necessarily need to specify the same language."
        }
      },
      "description": "Events allow for matching intents by event name instead of the natural language input. For instance, input `` can trigger a personalized welcome response. The parameter `name` may be used by the agent in the response: `\"Hello #welcome_event.name! What can I do for you today?\"`.",
      "type": "object"
    },
    "GoogleCloudDialogflowCxV3beta1ExportAgentResponse": {
      "id": "GoogleCloudDialogflowCxV3beta1ExportAgentResponse",
      "properties": {
        "agentUri": {
          "type": "string",
          "description": "The URI to a file containing the exported agent. This field is populated only if `agent_uri` is specified in ExportAgentRequest."
        },
        "agentContent": {
          "type": "string",
          "format": "byte",
          "description": "Uncompressed raw byte content for agent."
        }
      },
      "description": "The response message for Agents.ExportAgent.",
      "type": "object"
    },
    "GoogleCloudDialogflowV2IntentMessageListSelectItem": {
      "description": "An item in the list.",
      "id": "GoogleCloudDialogflowV2IntentMessageListSelectItem",
      "properties": {
        "image": {
          "$ref": "GoogleCloudDialogflowV2IntentMessageImage",
          "description": "Optional. The image to display."
        },
        "description": {
          "description": "Optional. The main text describing the item.",
          "type": "string"
        },
        "title": {
          "description": "Required. The title of the list item.",
          "type": "string"
        },
        "info": {
          "$ref": "GoogleCloudDialogflowV2IntentMessageSelectItemInfo",
          "description": "Required. Additional information about this option."
        }
      },
      "type": "object"
    },
    "GoogleCloudDialogflowV2beta1IntentMessageRbmSuggestedReply": {
      "type": "object",
      "id": "GoogleCloudDialogflowV2beta1IntentMessageRbmSuggestedReply",
      "description": "Rich Business Messaging (RBM) suggested reply that the user can click instead of typing in their own response.",
      "properties": {
        "postbackData": {
          "description": "Opaque payload that the Dialogflow receives in a user event when the user taps the suggested reply. This data will be also forwarded to webhook to allow performing custom business logic.",
          "type": "string"
        },
        "text": {
          "type": "string",
          "description": "Suggested reply text."
        }
      }
    },
    "GoogleCloudDialogflowV2beta1EventInput": {
      "type": "object",
      "properties": {
        "name": {
          "type": "string",
          "description": "Required. The unique identifier of the event."
        },
        "parameters": {
          "description": "The collection of parameters associated with the event. Depending on your protocol or client library language, this is a map, associative array, symbol table, dictionary, or JSON object composed of a collection of (MapKey, MapValue) pairs: - MapKey type: string - MapKey value: parameter name - MapValue type: - If parameter's entity type is a composite entity: map - Else: string or number, depending on parameter value type - MapValue value: - If parameter's entity type is a composite entity: map from composite entity property names to property values - Else: parameter value",
          "additionalProperties": {
            "description": "Properties of the object.",
            "type": "any"
          },
          "type": "object"
        },
        "languageCode": {
          "type": "string",
          "description": "Required. The language of this query. See [Language Support](https://cloud.google.com/dialogflow/docs/reference/language) for a list of the currently supported language codes. Note that queries in the same session do not necessarily need to specify the same language."
        }
      },
      "id": "GoogleCloudDialogflowV2beta1EventInput",
      "description": "Events allow for matching intents by event name instead of the natural language input. For instance, input `` can trigger a personalized welcome response. The parameter `name` may be used by the agent in the response: `\"Hello #welcome_event.name! What can I do for you today?\"`."
    },
    "GoogleCloudDialogflowV2beta1WebhookResponse": {
      "id": "GoogleCloudDialogflowV2beta1WebhookResponse",
      "description": "The response message for a webhook call. This response is validated by the Dialogflow server. If validation fails, an error will be returned in the QueryResult.diagnostic_info field. Setting JSON fields to an empty value with the wrong type is a common error. To avoid this error: - Use `\"\"` for empty strings - Use `{}` or `null` for empty objects - Use `[]` or `null` for empty arrays For more information, see the [Protocol Buffers Language Guide](https://developers.google.com/protocol-buffers/docs/proto3#json).",
      "properties": {
        "source": {
          "description": "Optional. A custom field used to identify the webhook source. Arbitrary strings are supported. When provided, Dialogflow uses this field to populate QueryResult.webhook_source sent to the integration or API caller.",
          "type": "string"
        },
        "fulfillmentText": {
          "description": "Optional. The text response message intended for the end-user. It is recommended to use `fulfillment_messages.text.text[0]` instead. When provided, Dialogflow uses this field to populate QueryResult.fulfillment_text sent to the integration or API caller.",
          "type": "string"
        },
        "payload": {
          "description": "Optional. This field can be used to pass custom data from your webhook to the integration or API caller. Arbitrary JSON objects are supported. When provided, Dialogflow uses this field to populate QueryResult.webhook_payload sent to the integration or API caller. This field is also used by the [Google Assistant integration](https://cloud.google.com/dialogflow/docs/integrations/aog) for rich response messages. See the format definition at [Google Assistant Dialogflow webhook format](https://developers.google.com/assistant/actions/build/json/dialogflow-webhook-json)",
          "additionalProperties": {
            "description": "Properties of the object.",
            "type": "any"
          },
          "type": "object"
        },
        "fulfillmentMessages": {
          "type": "array",
          "items": {
            "$ref": "GoogleCloudDialogflowV2beta1IntentMessage"
          },
          "description": "Optional. The rich response messages intended for the end-user. When provided, Dialogflow uses this field to populate QueryResult.fulfillment_messages sent to the integration or API caller."
        },
        "followupEventInput": {
          "$ref": "GoogleCloudDialogflowV2beta1EventInput",
          "description": "Optional. Invokes the supplied events. When this field is set, Dialogflow ignores the `fulfillment_text`, `fulfillment_messages`, and `payload` fields."
        },
        "outputContexts": {
          "type": "array",
          "description": "Optional. The collection of output contexts that will overwrite currently active contexts for the session and reset their lifespans. When provided, Dialogflow uses this field to populate QueryResult.output_contexts sent to the integration or API caller.",
          "items": {
            "$ref": "GoogleCloudDialogflowV2beta1Context"
          }
        },
        "endInteraction": {
          "description": "Optional. Indicates that this intent ends an interaction. Some integrations (e.g., Actions on Google or Dialogflow phone gateway) use this information to close interaction with an end user. Default is false.",
          "type": "boolean"
        },
        "sessionEntityTypes": {
          "type": "array",
          "items": {
            "$ref": "GoogleCloudDialogflowV2beta1SessionEntityType"
          },
          "description": "Optional. Additional session entity types to replace or extend developer entity types with. The entity synonyms apply to all languages and persist for the session. Setting this data from a webhook overwrites the session entity types that have been set using `detectIntent`, `streamingDetectIntent` or SessionEntityType management methods."
        }
      },
      "type": "object"
    },
    "GoogleCloudDialogflowV2beta1IntentMessageRbmSuggestion": {
      "id": "GoogleCloudDialogflowV2beta1IntentMessageRbmSuggestion",
      "type": "object",
      "properties": {
        "action": {
          "$ref": "GoogleCloudDialogflowV2beta1IntentMessageRbmSuggestedAction",
          "description": "Predefined client side actions that user can choose"
        },
        "reply": {
          "$ref": "GoogleCloudDialogflowV2beta1IntentMessageRbmSuggestedReply",
          "description": "Predefined replies for user to select instead of typing"
        }
      },
      "description": "Rich Business Messaging (RBM) suggestion. Suggestions allow user to easily select/click a predefined response or perform an action (like opening a web uri)."
    },
    "GoogleCloudDialogflowV2beta1IntentParameter": {
      "properties": {
        "mandatory": {
          "type": "boolean",
          "description": "Optional. Indicates whether the parameter is required. That is, whether the intent cannot be completed without collecting the parameter value."
        },
        "entityTypeDisplayName": {
          "type": "string",
          "description": "Optional. The name of the entity type, prefixed with `@`, that describes values of the parameter. If the parameter is required, this must be provided."
        },
        "prompts": {
          "items": {
            "type": "string"
          },
          "type": "array",
          "description": "Optional. The collection of prompts that the agent can present to the user in order to collect a value for the parameter."
        },
        "name": {
          "description": "The unique identifier of this parameter.",
          "type": "string"
        },
        "value": {
          "description": "Optional. The definition of the parameter value. It can be: - a constant string, - a parameter value defined as `$parameter_name`, - an original parameter value defined as `$parameter_name.original`, - a parameter value from some context defined as `#context_name.parameter_name`.",
          "type": "string"
        },
        "defaultValue": {
          "type": "string",
          "description": "Optional. The default value to use when the `value` yields an empty result. Default values can be extracted from contexts by using the following syntax: `#context_name.parameter_name`."
        },
        "displayName": {
          "type": "string",
          "description": "Required. The name of the parameter."
        },
        "isList": {
          "type": "boolean",
          "description": "Optional. Indicates whether the parameter represents a list of values."
        }
      },
      "description": "Represents intent parameters.",
      "id": "GoogleCloudDialogflowV2beta1IntentParameter",
      "type": "object"
    },
    "GoogleCloudDialogflowV2EntityType": {
      "properties": {
        "displayName": {
          "type": "string",
          "description": "Required. The name of the entity type."
        },
        "autoExpansionMode": {
          "enum": [
            "AUTO_EXPANSION_MODE_UNSPECIFIED",
            "AUTO_EXPANSION_MODE_DEFAULT"
          ],
          "type": "string",
          "enumDescriptions": [
            "Auto expansion disabled for the entity.",
            "Allows an agent to recognize values that have not been explicitly listed in the entity."
          ],
          "description": "Optional. Indicates whether the entity type can be automatically expanded."
        },
        "kind": {
          "type": "string",
          "enum": [
            "KIND_UNSPECIFIED",
            "KIND_MAP",
            "KIND_LIST",
            "KIND_REGEXP"
          ],
          "description": "Required. Indicates the kind of entity type.",
          "enumDescriptions": [
            "Not specified. This value should be never used.",
            "Map entity types allow mapping of a group of synonyms to a reference value.",
            "List entity types contain a set of entries that do not map to reference values. However, list entity types can contain references to other entity types (with or without aliases).",
            "Regexp entity types allow to specify regular expressions in entries values."
          ]
        },
        "name": {
          "type": "string",
          "description": "The unique identifier of the entity type. Required for EntityTypes.UpdateEntityType and EntityTypes.BatchUpdateEntityTypes methods. Format: `projects//agent/entityTypes/`."
        },
        "entities": {
          "type": "array",
          "description": "Optional. The collection of entity entries associated with the entity type.",
          "items": {
            "$ref": "GoogleCloudDialogflowV2EntityTypeEntity"
          }
        },
        "enableFuzzyExtraction": {
          "type": "boolean",
          "description": "Optional. Enables fuzzy entity extraction during classification."
        }
      },
      "type": "object",
      "description": "Each intent parameter has a type, called the entity type, which dictates exactly how data from an end-user expression is extracted. Dialogflow provides predefined system entities that can match many common types of data. For example, there are system entities for matching dates, times, colors, email addresses, and so on. You can also create your own custom entities for matching custom data. For example, you could define a vegetable entity that can match the types of vegetables available for purchase with a grocery store agent. For more information, see the [Entity guide](https://cloud.google.com/dialogflow/docs/entities-overview).",
      "id": "GoogleCloudDialogflowV2EntityType"
    },
    "GoogleCloudDialogflowV2beta1SentimentAnalysisResult": {
      "description": "The result of sentiment analysis. Sentiment analysis inspects user input and identifies the prevailing subjective opinion, especially to determine a user's attitude as positive, negative, or neutral. For Participants.AnalyzeContent, it needs to be configured in DetectIntentRequest.query_params. For Participants.StreamingAnalyzeContent, it needs to be configured in StreamingDetectIntentRequest.query_params. And for Participants.AnalyzeContent and Participants.StreamingAnalyzeContent, it needs to be configured in ConversationProfile.human_agent_assistant_config",
      "properties": {
        "queryTextSentiment": {
          "$ref": "GoogleCloudDialogflowV2beta1Sentiment",
          "description": "The sentiment analysis result for `query_text`."
        }
      },
      "id": "GoogleCloudDialogflowV2beta1SentimentAnalysisResult",
      "type": "object"
    },
    "GoogleCloudDialogflowV2beta1IntentMessageMediaContent": {
      "type": "object",
      "properties": {
        "mediaType": {
          "description": "Optional. What type of media is the content (ie \"audio\").",
          "type": "string",
          "enumDescriptions": [
            "Unspecified.",
            "Response media type is audio."
          ],
          "enum": [
            "RESPONSE_MEDIA_TYPE_UNSPECIFIED",
            "AUDIO"
          ]
        },
        "mediaObjects": {
          "description": "Required. List of media objects.",
          "type": "array",
          "items": {
            "$ref": "GoogleCloudDialogflowV2beta1IntentMessageMediaContentResponseMediaObject"
          }
        }
      },
      "description": "The media content card for Actions on Google.",
      "id": "GoogleCloudDialogflowV2beta1IntentMessageMediaContent"
    },
    "GoogleCloudDialogflowV2IntentMessageSimpleResponses": {
      "type": "object",
      "description": "The collection of simple response candidates. This message in `QueryResult.fulfillment_messages` and `WebhookResponse.fulfillment_messages` should contain only one `SimpleResponse`.",
      "properties": {
        "simpleResponses": {
          "items": {
            "$ref": "GoogleCloudDialogflowV2IntentMessageSimpleResponse"
          },
          "description": "Required. The list of simple responses.",
          "type": "array"
        }
      },
      "id": "GoogleCloudDialogflowV2IntentMessageSimpleResponses"
    },
    "GoogleCloudDialogflowV2beta1IntentMessageListSelectItem": {
      "properties": {
        "description": {
          "description": "Optional. The main text describing the item.",
          "type": "string"
        },
        "info": {
          "$ref": "GoogleCloudDialogflowV2beta1IntentMessageSelectItemInfo",
          "description": "Required. Additional information about this option."
        },
        "image": {
          "$ref": "GoogleCloudDialogflowV2beta1IntentMessageImage",
          "description": "Optional. The image to display."
        },
        "title": {
          "description": "Required. The title of the list item.",
          "type": "string"
        }
      },
      "description": "An item in the list.",
      "type": "object",
      "id": "GoogleCloudDialogflowV2beta1IntentMessageListSelectItem"
    },
    "GoogleCloudDialogflowV2IntentMessageBrowseCarouselCardBrowseCarouselCardItem": {
      "type": "object",
      "properties": {
        "title": {
          "type": "string",
          "description": "Required. Title of the carousel item. Maximum of two lines of text."
        },
        "image": {
          "description": "Optional. Hero image for the carousel item.",
          "$ref": "GoogleCloudDialogflowV2IntentMessageImage"
        },
        "description": {
          "description": "Optional. Description of the carousel item. Maximum of four lines of text.",
          "type": "string"
        },
        "openUriAction": {
          "$ref": "GoogleCloudDialogflowV2IntentMessageBrowseCarouselCardBrowseCarouselCardItemOpenUrlAction",
          "description": "Required. Action to present to the user."
        },
        "footer": {
          "type": "string",
          "description": "Optional. Text that appears at the bottom of the Browse Carousel Card. Maximum of one line of text."
        }
      },
      "id": "GoogleCloudDialogflowV2IntentMessageBrowseCarouselCardBrowseCarouselCardItem",
      "description": "Browsing carousel tile"
    },
    "GoogleCloudDialogflowV2IntentMessageTableCard": {
      "id": "GoogleCloudDialogflowV2IntentMessageTableCard",
      "type": "object",
      "properties": {
        "rows": {
          "items": {
            "$ref": "GoogleCloudDialogflowV2IntentMessageTableCardRow"
          },
          "type": "array",
          "description": "Optional. Rows in this table of data."
        },
        "subtitle": {
          "description": "Optional. Subtitle to the title.",
          "type": "string"
        },
        "image": {
          "$ref": "GoogleCloudDialogflowV2IntentMessageImage",
          "description": "Optional. Image which should be displayed on the card."
        },
        "buttons": {
          "items": {
            "$ref": "GoogleCloudDialogflowV2IntentMessageBasicCardButton"
          },
          "type": "array",
          "description": "Optional. List of buttons for the card."
        },
        "title": {
          "type": "string",
          "description": "Required. Title of the card."
        },
        "columnProperties": {
          "description": "Optional. Display properties for the columns in this table.",
          "type": "array",
          "items": {
            "$ref": "GoogleCloudDialogflowV2IntentMessageColumnProperties"
          }
        }
      },
      "description": "Table card for Actions on Google."
    },
    "GoogleCloudDialogflowV2beta1IntentMessageTableCardCell": {
      "type": "object",
      "properties": {
        "text": {
          "description": "Required. Text in this cell.",
          "type": "string"
        }
      },
      "description": "Cell of TableCardRow.",
      "id": "GoogleCloudDialogflowV2beta1IntentMessageTableCardCell"
    },
    "GoogleCloudDialogflowV2EntityTypeEntity": {
      "description": "An **entity entry** for an associated entity type.",
      "id": "GoogleCloudDialogflowV2EntityTypeEntity",
      "properties": {
        "value": {
          "type": "string",
          "description": "Required. The primary value associated with this entity entry. For example, if the entity type is *vegetable*, the value could be *scallions*. For `KIND_MAP` entity types: * A reference value to be used in place of synonyms. For `KIND_LIST` entity types: * A string that can contain references to other entity types (with or without aliases)."
        },
        "synonyms": {
          "description": "Required. A collection of value synonyms. For example, if the entity type is *vegetable*, and `value` is *scallions*, a synonym could be *green onions*. For `KIND_LIST` entity types: * This collection must contain exactly one synonym equal to `value`.",
          "items": {
            "type": "string"
          },
          "type": "array"
        }
      },
      "type": "object"
    },
    "GoogleCloudDialogflowCxV3beta1ResponseMessageOutputAudioText": {
      "id": "GoogleCloudDialogflowCxV3beta1ResponseMessageOutputAudioText",
      "description": "A text or ssml response that is preferentially used for TTS output audio synthesis, as described in the comment on the ResponseMessage message.",
      "properties": {
        "ssml": {
          "description": "The SSML text to be synthesized. For more information, see [SSML](/speech/text-to-speech/docs/ssml).",
          "type": "string"
        },
        "text": {
          "type": "string",
          "description": "The raw text to be synthesized."
        }
      },
      "type": "object"
    },
    "GoogleCloudDialogflowCxV3beta1PageInfo": {
      "properties": {
        "currentPage": {
          "description": "Always present for WebhookRequest. Ignored for WebhookResponse. The unique identifier of the current page. Format: `projects//locations//agents//flows//pages/`.",
          "type": "string"
        },
        "formInfo": {
          "$ref": "GoogleCloudDialogflowCxV3beta1PageInfoFormInfo",
          "description": "Optional for both WebhookRequest and WebhookResponse. Information about the form."
        }
      },
      "type": "object",
      "id": "GoogleCloudDialogflowCxV3beta1PageInfo",
      "description": "Represents page information communicated to and from the webhook."
    },
    "GoogleCloudDialogflowV2beta1QueryResult": {
      "type": "object",
      "description": "Represents the result of conversational query or event processing.",
      "properties": {
        "parameters": {
          "additionalProperties": {
            "type": "any",
            "description": "Properties of the object."
          },
          "description": "The collection of extracted parameters. Depending on your protocol or client library language, this is a map, associative array, symbol table, dictionary, or JSON object composed of a collection of (MapKey, MapValue) pairs: - MapKey type: string - MapKey value: parameter name - MapValue type: - If parameter's entity type is a composite entity: map - Else: string or number, depending on parameter value type - MapValue value: - If parameter's entity type is a composite entity: map from composite entity property names to property values - Else: parameter value",
          "type": "object"
        },
        "action": {
          "description": "The action name from the matched intent.",
          "type": "string"
        },
        "diagnosticInfo": {
          "type": "object",
          "additionalProperties": {
            "description": "Properties of the object.",
            "type": "any"
          },
          "description": "Free-form diagnostic information for the associated detect intent request. The fields of this data can change without notice, so you should not write code that depends on its structure. The data may contain: - webhook call latency - webhook errors"
        },
        "intent": {
          "$ref": "GoogleCloudDialogflowV2beta1Intent",
          "description": "The intent that matched the conversational query. Some, not all fields are filled in this message, including but not limited to: `name`, `display_name`, `end_interaction` and `is_fallback`."
        },
        "languageCode": {
          "description": "The language that was triggered during intent detection. See [Language Support](https://cloud.google.com/dialogflow/docs/reference/language) for a list of the currently supported language codes.",
          "type": "string"
        },
        "speechRecognitionConfidence": {
          "format": "float",
          "type": "number",
          "description": "The Speech recognition confidence between 0.0 and 1.0. A higher number indicates an estimated greater likelihood that the recognized words are correct. The default of 0.0 is a sentinel value indicating that confidence was not set. This field is not guaranteed to be accurate or set. In particular this field isn't set for StreamingDetectIntent since the streaming endpoint has separate confidence estimates per portion of the audio in StreamingRecognitionResult."
        },
        "knowledgeAnswers": {
          "description": "The result from Knowledge Connector (if any), ordered by decreasing `KnowledgeAnswers.match_confidence`.",
          "$ref": "GoogleCloudDialogflowV2beta1KnowledgeAnswers"
        },
        "fulfillmentText": {
          "description": "The text to be pronounced to the user or shown on the screen. Note: This is a legacy field, `fulfillment_messages` should be preferred.",
          "type": "string"
        },
        "intentDetectionConfidence": {
          "format": "float",
          "description": "The intent detection confidence. Values range from 0.0 (completely uncertain) to 1.0 (completely certain). This value is for informational purpose only and is only used to help match the best intent within the classification threshold. This value may change for the same end-user expression at any time due to a model retraining or change in implementation. If there are `multiple knowledge_answers` messages, this value is set to the greatest `knowledgeAnswers.match_confidence` value in the list.",
          "type": "number"
        },
        "allRequiredParamsPresent": {
          "type": "boolean",
          "description": "This field is set to: - `false` if the matched intent has required parameters and not all of the required parameter values have been collected. - `true` if all required parameter values have been collected, or if the matched intent doesn't contain any required parameters."
        },
        "outputContexts": {
          "type": "array",
          "items": {
            "$ref": "GoogleCloudDialogflowV2beta1Context"
          },
          "description": "The collection of output contexts. If applicable, `output_contexts.parameters` contains entries with name `.original` containing the original parameter values before the query."
        },
        "webhookPayload": {
          "additionalProperties": {
            "type": "any",
            "description": "Properties of the object."
          },
          "type": "object",
          "description": "If the query was fulfilled by a webhook call, this field is set to the value of the `payload` field returned in the webhook response."
        },
        "fulfillmentMessages": {
          "items": {
            "$ref": "GoogleCloudDialogflowV2beta1IntentMessage"
          },
          "type": "array",
          "description": "The collection of rich messages to present to the user."
        },
        "queryText": {
          "description": "The original conversational query text: - If natural language text was provided as input, `query_text` contains a copy of the input. - If natural language speech audio was provided as input, `query_text` contains the speech recognition result. If speech recognizer produced multiple alternatives, a particular one is picked. - If automatic spell correction is enabled, `query_text` will contain the corrected user input.",
          "type": "string"
        },
        "sentimentAnalysisResult": {
          "description": "The sentiment analysis result, which depends on the `sentiment_analysis_request_config` specified in the request.",
          "$ref": "GoogleCloudDialogflowV2beta1SentimentAnalysisResult"
        },
        "webhookSource": {
          "description": "If the query was fulfilled by a webhook call, this field is set to the value of the `source` field returned in the webhook response.",
          "type": "string"
        }
      },
      "id": "GoogleCloudDialogflowV2beta1QueryResult"
    },
    "GoogleCloudDialogflowV3alpha1ExportAgentResponse": {
      "type": "object",
      "description": "The response message for Agents.ExportAgent.",
      "properties": {
        "agentContent": {
          "format": "byte",
          "description": "Uncompressed raw byte content for agent.",
          "type": "string"
        },
        "agentUri": {
          "type": "string",
          "description": "The URI to a file containing the exported agent. This field is populated only if `agent_uri` is specified in ExportAgentRequest."
        }
      },
      "id": "GoogleCloudDialogflowV3alpha1ExportAgentResponse"
    },
    "GoogleCloudDialogflowV2beta1IntentMessageTableCardRow": {
      "properties": {
        "dividerAfter": {
          "type": "boolean",
          "description": "Optional. Whether to add a visual divider after this row."
        },
        "cells": {
          "description": "Optional. List of cells that make up this row.",
          "type": "array",
          "items": {
            "$ref": "GoogleCloudDialogflowV2beta1IntentMessageTableCardCell"
          }
        }
      },
      "description": "Row of TableCard.",
      "type": "object",
      "id": "GoogleCloudDialogflowV2beta1IntentMessageTableCardRow"
    },
    "GoogleCloudDialogflowCxV3beta1WebhookResponse": {
      "properties": {
        "targetFlow": {
          "type": "string",
          "description": "The target flow to transition to. Format: `projects//locations//agents//flows/`."
        },
        "fulfillmentResponse": {
          "description": "The fulfillment response to send to the user. This field can be omitted by the webhook if it does not intend to send any response to the user.",
          "$ref": "GoogleCloudDialogflowCxV3beta1WebhookResponseFulfillmentResponse"
        },
        "pageInfo": {
          "description": "Information about page status. This field can be omitted by the webhook if it does not intend to modify page status.",
          "$ref": "GoogleCloudDialogflowCxV3beta1PageInfo"
        },
        "targetPage": {
          "description": "The target page to transition to. Format: `projects//locations//agents//flows//pages/`.",
          "type": "string"
        },
        "payload": {
          "type": "object",
          "additionalProperties": {
            "type": "any",
            "description": "Properties of the object."
          },
          "description": "Value to append directly to QueryResult.webhook_payloads."
        },
        "sessionInfo": {
          "description": "Information about session status. This field can be omitted by the webhook if it does not intend to modify session status.",
          "$ref": "GoogleCloudDialogflowCxV3beta1SessionInfo"
        }
      },
      "type": "object",
      "description": "The response message for a webhook call.",
      "id": "GoogleCloudDialogflowCxV3beta1WebhookResponse"
    },
    "GoogleCloudDialogflowV2QueryResult": {
      "type": "object",
      "properties": {
        "webhookPayload": {
          "type": "object",
          "description": "If the query was fulfilled by a webhook call, this field is set to the value of the `payload` field returned in the webhook response.",
          "additionalProperties": {
            "type": "any",
            "description": "Properties of the object."
          }
        },
        "action": {
          "description": "The action name from the matched intent.",
          "type": "string"
        },
        "parameters": {
          "type": "object",
          "description": "The collection of extracted parameters. Depending on your protocol or client library language, this is a map, associative array, symbol table, dictionary, or JSON object composed of a collection of (MapKey, MapValue) pairs: - MapKey type: string - MapKey value: parameter name - MapValue type: - If parameter's entity type is a composite entity: map - Else: string or number, depending on parameter value type - MapValue value: - If parameter's entity type is a composite entity: map from composite entity property names to property values - Else: parameter value",
          "additionalProperties": {
            "description": "Properties of the object.",
            "type": "any"
          }
        },
        "queryText": {
          "description": "The original conversational query text: - If natural language text was provided as input, `query_text` contains a copy of the input. - If natural language speech audio was provided as input, `query_text` contains the speech recognition result. If speech recognizer produced multiple alternatives, a particular one is picked. - If automatic spell correction is enabled, `query_text` will contain the corrected user input.",
          "type": "string"
        },
        "webhookSource": {
          "description": "If the query was fulfilled by a webhook call, this field is set to the value of the `source` field returned in the webhook response.",
          "type": "string"
        },
        "intent": {
          "description": "The intent that matched the conversational query. Some, not all fields are filled in this message, including but not limited to: `name`, `display_name`, `end_interaction` and `is_fallback`.",
          "$ref": "GoogleCloudDialogflowV2Intent"
        },
        "diagnosticInfo": {
          "type": "object",
          "description": "Free-form diagnostic information for the associated detect intent request. The fields of this data can change without notice, so you should not write code that depends on its structure. The data may contain: - webhook call latency - webhook errors",
          "additionalProperties": {
            "description": "Properties of the object.",
            "type": "any"
          }
        },
        "sentimentAnalysisResult": {
          "description": "The sentiment analysis result, which depends on the `sentiment_analysis_request_config` specified in the request.",
          "$ref": "GoogleCloudDialogflowV2SentimentAnalysisResult"
        },
        "allRequiredParamsPresent": {
          "type": "boolean",
          "description": "This field is set to: - `false` if the matched intent has required parameters and not all of the required parameter values have been collected. - `true` if all required parameter values have been collected, or if the matched intent doesn't contain any required parameters."
        },
        "outputContexts": {
          "type": "array",
          "description": "The collection of output contexts. If applicable, `output_contexts.parameters` contains entries with name `.original` containing the original parameter values before the query.",
          "items": {
            "$ref": "GoogleCloudDialogflowV2Context"
          }
        },
        "fulfillmentText": {
          "description": "The text to be pronounced to the user or shown on the screen. Note: This is a legacy field, `fulfillment_messages` should be preferred.",
          "type": "string"
        },
        "intentDetectionConfidence": {
          "format": "float",
          "description": "The intent detection confidence. Values range from 0.0 (completely uncertain) to 1.0 (completely certain). This value is for informational purpose only and is only used to help match the best intent within the classification threshold. This value may change for the same end-user expression at any time due to a model retraining or change in implementation. If there are `multiple knowledge_answers` messages, this value is set to the greatest `knowledgeAnswers.match_confidence` value in the list.",
          "type": "number"
        },
        "speechRecognitionConfidence": {
          "description": "The Speech recognition confidence between 0.0 and 1.0. A higher number indicates an estimated greater likelihood that the recognized words are correct. The default of 0.0 is a sentinel value indicating that confidence was not set. This field is not guaranteed to be accurate or set. In particular this field isn't set for StreamingDetectIntent since the streaming endpoint has separate confidence estimates per portion of the audio in StreamingRecognitionResult.",
          "format": "float",
          "type": "number"
        },
        "languageCode": {
          "description": "The language that was triggered during intent detection. See [Language Support](https://cloud.google.com/dialogflow/docs/reference/language) for a list of the currently supported language codes.",
          "type": "string"
        },
        "fulfillmentMessages": {
          "type": "array",
          "description": "The collection of rich messages to present to the user.",
          "items": {
            "$ref": "GoogleCloudDialogflowV2IntentMessage"
          }
        }
      },
      "description": "Represents the result of conversational query or event processing.",
      "id": "GoogleCloudDialogflowV2QueryResult"
    },
    "GoogleCloudDialogflowV2beta1KnowledgeAnswers": {
      "description": "Represents the result of querying a Knowledge base.",
      "properties": {
        "answers": {
          "items": {
            "$ref": "GoogleCloudDialogflowV2beta1KnowledgeAnswersAnswer"
          },
          "type": "array",
          "description": "A list of answers from Knowledge Connector."
        }
      },
      "id": "GoogleCloudDialogflowV2beta1KnowledgeAnswers",
      "type": "object"
    },
    "GoogleCloudDialogflowV2IntentMessage": {
      "properties": {
        "listSelect": {
          "$ref": "GoogleCloudDialogflowV2IntentMessageListSelect",
          "description": "The list card response for Actions on Google."
        },
        "suggestions": {
          "description": "The suggestion chips for Actions on Google.",
          "$ref": "GoogleCloudDialogflowV2IntentMessageSuggestions"
        },
        "basicCard": {
          "$ref": "GoogleCloudDialogflowV2IntentMessageBasicCard",
          "description": "The basic card response for Actions on Google."
        },
        "simpleResponses": {
          "$ref": "GoogleCloudDialogflowV2IntentMessageSimpleResponses",
          "description": "The voice and text-only responses for Actions on Google."
        },
        "tableCard": {
          "$ref": "GoogleCloudDialogflowV2IntentMessageTableCard",
          "description": "Table card for Actions on Google."
        },
        "mediaContent": {
          "description": "The media content card for Actions on Google.",
          "$ref": "GoogleCloudDialogflowV2IntentMessageMediaContent"
        },
        "carouselSelect": {
          "description": "The carousel card response for Actions on Google.",
          "$ref": "GoogleCloudDialogflowV2IntentMessageCarouselSelect"
        },
        "browseCarouselCard": {
          "description": "Browse carousel card for Actions on Google.",
          "$ref": "GoogleCloudDialogflowV2IntentMessageBrowseCarouselCard"
        },
        "image": {
          "description": "The image response.",
          "$ref": "GoogleCloudDialogflowV2IntentMessageImage"
        },
        "linkOutSuggestion": {
          "$ref": "GoogleCloudDialogflowV2IntentMessageLinkOutSuggestion",
          "description": "The link out suggestion chip for Actions on Google."
        },
        "text": {
          "$ref": "GoogleCloudDialogflowV2IntentMessageText",
          "description": "The text response."
        },
        "quickReplies": {
          "$ref": "GoogleCloudDialogflowV2IntentMessageQuickReplies",
          "description": "The quick replies response."
        },
        "platform": {
          "enum": [
            "PLATFORM_UNSPECIFIED",
            "FACEBOOK",
            "SLACK",
            "TELEGRAM",
            "KIK",
            "SKYPE",
            "LINE",
            "VIBER",
            "ACTIONS_ON_GOOGLE",
            "GOOGLE_HANGOUTS"
          ],
          "description": "Optional. The platform that this message is intended for.",
          "enumDescriptions": [
            "Default platform.",
            "Facebook.",
            "Slack.",
            "Telegram.",
            "Kik.",
            "Skype.",
            "Line.",
            "Viber.",
            "Google Assistant See [Dialogflow webhook format](https://developers.google.com/assistant/actions/build/json/dialogflow-webhook-json)",
            "Google Hangouts."
          ],
          "type": "string"
        },
        "card": {
          "description": "The card response.",
          "$ref": "GoogleCloudDialogflowV2IntentMessageCard"
        },
        "payload": {
          "description": "A custom platform-specific response.",
          "type": "object",
          "additionalProperties": {
            "description": "Properties of the object.",
            "type": "any"
          }
        }
      },
      "type": "object",
      "description": "A rich response message. Corresponds to the intent `Response` field in the Dialogflow console. For more information, see [Rich response messages](https://cloud.google.com/dialogflow/docs/intents-rich-messages).",
      "id": "GoogleCloudDialogflowV2IntentMessage"
    },
    "GoogleCloudDialogflowV2IntentTrainingPhrasePart": {
      "description": "Represents a part of a training phrase.",
      "type": "object",
      "properties": {
        "alias": {
          "description": "Optional. The parameter name for the value extracted from the annotated part of the example. This field is required for annotated parts of the training phrase.",
          "type": "string"
        },
        "userDefined": {
          "type": "boolean",
          "description": "Optional. Indicates whether the text was manually annotated. This field is set to true when the Dialogflow Console is used to manually annotate the part. When creating an annotated part with the API, you must set this to true."
        },
        "text": {
          "description": "Required. The text for this part.",
          "type": "string"
        },
        "entityType": {
          "description": "Optional. The entity type name prefixed with `@`. This field is required for annotated parts of the training phrase.",
          "type": "string"
        }
      },
      "id": "GoogleCloudDialogflowV2IntentTrainingPhrasePart"
    },
    "GoogleCloudDialogflowV2Context": {
      "description": "Dialogflow contexts are similar to natural language context. If a person says to you \"they are orange\", you need context in order to understand what \"they\" is referring to. Similarly, for Dialogflow to handle an end-user expression like that, it needs to be provided with context in order to correctly match an intent. Using contexts, you can control the flow of a conversation. You can configure contexts for an intent by setting input and output contexts, which are identified by string names. When an intent is matched, any configured output contexts for that intent become active. While any contexts are active, Dialogflow is more likely to match intents that are configured with input contexts that correspond to the currently active contexts. For more information about context, see the [Contexts guide](https://cloud.google.com/dialogflow/docs/contexts-overview).",
      "properties": {
        "lifespanCount": {
          "description": "Optional. The number of conversational query requests after which the context expires. The default is `0`. If set to `0`, the context expires immediately. Contexts expire automatically after 20 minutes if there are no matching queries.",
          "type": "integer",
          "format": "int32"
        },
        "parameters": {
          "type": "object",
          "additionalProperties": {
            "description": "Properties of the object.",
            "type": "any"
          },
          "description": "Optional. The collection of parameters associated with this context. Depending on your protocol or client library language, this is a map, associative array, symbol table, dictionary, or JSON object composed of a collection of (MapKey, MapValue) pairs: - MapKey type: string - MapKey value: parameter name - MapValue type: - If parameter's entity type is a composite entity: map - Else: string or number, depending on parameter value type - MapValue value: - If parameter's entity type is a composite entity: map from composite entity property names to property values - Else: parameter value"
        },
        "name": {
          "type": "string",
          "description": "Required. The unique identifier of the context. Format: `projects//agent/sessions//contexts/`, or `projects//agent/environments//users//sessions//contexts/`. The `Context ID` is always converted to lowercase, may only contain characters in a-zA-Z0-9_-% and may be at most 250 bytes long. If `Environment ID` is not specified, we assume default 'draft' environment. If `User ID` is not specified, we assume default '-' user. The following context names are reserved for internal use by Dialogflow. You should not use these contexts or create contexts with these names: * `__system_counters__` * `*_id_dialog_context` * `*_dialog_params_size`"
        }
      },
      "type": "object",
      "id": "GoogleCloudDialogflowV2Context"
    },
    "GoogleCloudDialogflowV2beta1IntentMessageImage": {
      "description": "The image response message.",
      "type": "object",
      "id": "GoogleCloudDialogflowV2beta1IntentMessageImage",
      "properties": {
        "imageUri": {
          "type": "string",
          "description": "Optional. The public URI to an image file."
        },
        "accessibilityText": {
          "description": "A text description of the image to be used for accessibility, e.g., screen readers. Required if image_uri is set for CarouselSelect.",
          "type": "string"
        }
      }
    },
    "GoogleCloudDialogflowCxV3beta1WebhookRequest": {
      "properties": {
        "messages": {
          "type": "array",
          "items": {
            "$ref": "GoogleCloudDialogflowCxV3beta1ResponseMessage"
          },
          "description": "The list of rich message responses to present to the user. Webhook can choose to append or replace this list in WebhookResponse.fulfillment_response;"
        },
        "fulfillmentInfo": {
          "$ref": "GoogleCloudDialogflowCxV3beta1WebhookRequestFulfillmentInfo",
          "description": "Always present. Information about the fulfillment that triggered this webhook call."
        },
        "detectIntentResponseId": {
          "type": "string",
          "description": "Always present. The unique identifier of the DetectIntentResponse that will be returned to the API caller."
        },
        "pageInfo": {
          "description": "Information about page status.",
          "$ref": "GoogleCloudDialogflowCxV3beta1PageInfo"
        },
        "intentInfo": {
          "$ref": "GoogleCloudDialogflowCxV3beta1WebhookRequestIntentInfo",
          "description": "Information about the last matched intent."
        },
        "sessionInfo": {
          "$ref": "GoogleCloudDialogflowCxV3beta1SessionInfo",
          "description": "Information about session status."
        },
        "payload": {
          "type": "object",
          "description": "Custom data set in QueryParameters.payload.",
          "additionalProperties": {
            "description": "Properties of the object.",
            "type": "any"
          }
        }
      },
      "description": "The request message for a webhook call.",
      "type": "object",
      "id": "GoogleCloudDialogflowCxV3beta1WebhookRequest"
    },
    "GoogleCloudDialogflowV2beta1IntentMessageQuickReplies": {
      "description": "The quick replies response message.",
      "id": "GoogleCloudDialogflowV2beta1IntentMessageQuickReplies",
      "properties": {
        "title": {
          "type": "string",
          "description": "Optional. The title of the collection of quick replies."
        },
        "quickReplies": {
          "type": "array",
          "description": "Optional. The collection of quick replies.",
          "items": {
            "type": "string"
          }
        }
      },
      "type": "object"
    },
    "GoogleCloudDialogflowV2Intent": {
      "id": "GoogleCloudDialogflowV2Intent",
      "properties": {
        "defaultResponsePlatforms": {
          "type": "array",
          "items": {
            "enum": [
              "PLATFORM_UNSPECIFIED",
              "FACEBOOK",
              "SLACK",
              "TELEGRAM",
              "KIK",
              "SKYPE",
              "LINE",
              "VIBER",
              "ACTIONS_ON_GOOGLE",
              "GOOGLE_HANGOUTS"
            ],
            "type": "string",
            "enumDescriptions": [
              "Default platform.",
              "Facebook.",
              "Slack.",
              "Telegram.",
              "Kik.",
              "Skype.",
              "Line.",
              "Viber.",
              "Google Assistant See [Dialogflow webhook format](https://developers.google.com/assistant/actions/build/json/dialogflow-webhook-json)",
              "Google Hangouts."
            ]
          },
          "enumDescriptions": [
            "Default platform.",
            "Facebook.",
            "Slack.",
            "Telegram.",
            "Kik.",
            "Skype.",
            "Line.",
            "Viber.",
            "Google Assistant See [Dialogflow webhook format](https://developers.google.com/assistant/actions/build/json/dialogflow-webhook-json)",
            "Google Hangouts."
          ],
          "description": "Optional. The list of platforms for which the first responses will be copied from the messages in PLATFORM_UNSPECIFIED (i.e. default platform)."
        },
        "name": {
          "type": "string",
          "description": "Optional. The unique identifier of this intent. Required for Intents.UpdateIntent and Intents.BatchUpdateIntents methods. Format: `projects//agent/intents/`."
        },
        "parameters": {
          "description": "Optional. The collection of parameters associated with the intent.",
          "type": "array",
          "items": {
            "$ref": "GoogleCloudDialogflowV2IntentParameter"
          }
        },
        "isFallback": {
          "type": "boolean",
          "description": "Optional. Indicates whether this is a fallback intent."
        },
        "messages": {
          "description": "Optional. The collection of rich messages corresponding to the `Response` field in the Dialogflow console.",
          "type": "array",
          "items": {
            "$ref": "GoogleCloudDialogflowV2IntentMessage"
          }
        },
        "priority": {
          "description": "Optional. The priority of this intent. Higher numbers represent higher priorities. - If the supplied value is unspecified or 0, the service translates the value to 500,000, which corresponds to the `Normal` priority in the console. - If the supplied value is negative, the intent is ignored in runtime detect intent requests.",
          "format": "int32",
          "type": "integer"
        },
        "parentFollowupIntentName": {
          "type": "string",
          "description": "Read-only after creation. The unique identifier of the parent intent in the chain of followup intents. You can set this field when creating an intent, for example with CreateIntent or BatchUpdateIntents, in order to make this intent a followup intent. It identifies the parent followup intent. Format: `projects//agent/intents/`."
        },
        "outputContexts": {
          "type": "array",
          "items": {
            "$ref": "GoogleCloudDialogflowV2Context"
          },
          "description": "Optional. The collection of contexts that are activated when the intent is matched. Context messages in this collection should not set the parameters field. Setting the `lifespan_count` to 0 will reset the context when the intent is matched. Format: `projects//agent/sessions/-/contexts/`."
        },
        "action": {
          "type": "string",
          "description": "Optional. The name of the action associated with the intent. Note: The action name must not contain whitespaces."
        },
        "webhookState": {
          "enum": [
            "WEBHOOK_STATE_UNSPECIFIED",
            "WEBHOOK_STATE_ENABLED",
            "WEBHOOK_STATE_ENABLED_FOR_SLOT_FILLING"
          ],
          "enumDescriptions": [
            "Webhook is disabled in the agent and in the intent.",
            "Webhook is enabled in the agent and in the intent.",
            "Webhook is enabled in the agent and in the intent. Also, each slot filling prompt is forwarded to the webhook."
          ],
          "description": "Optional. Indicates whether webhooks are enabled for the intent.",
          "type": "string"
        },
        "events": {
          "items": {
            "type": "string"
          },
          "type": "array",
          "description": "Optional. The collection of event names that trigger the intent. If the collection of input contexts is not empty, all of the contexts must be present in the active user session for an event to trigger this intent. Event names are limited to 150 characters."
        },
        "inputContextNames": {
          "type": "array",
          "description": "Optional. The list of context names required for this intent to be triggered. Format: `projects//agent/sessions/-/contexts/`.",
          "items": {
            "type": "string"
          }
        },
        "mlDisabled": {
          "description": "Optional. Indicates whether Machine Learning is disabled for the intent. Note: If `ml_disabled` setting is set to true, then this intent is not taken into account during inference in `ML ONLY` match mode. Also, auto-markup in the UI is turned off.",
          "type": "boolean"
        },
        "displayName": {
          "type": "string",
          "description": "Required. The name of this intent."
        },
        "trainingPhrases": {
          "description": "Optional. The collection of examples that the agent is trained on.",
          "type": "array",
          "items": {
            "$ref": "GoogleCloudDialogflowV2IntentTrainingPhrase"
          }
        },
        "rootFollowupIntentName": {
          "type": "string",
          "description": "Read-only. The unique identifier of the root intent in the chain of followup intents. It identifies the correct followup intents chain for this intent. We populate this field only in the output. Format: `projects//agent/intents/`."
        },
        "followupIntentInfo": {
          "items": {
            "$ref": "GoogleCloudDialogflowV2IntentFollowupIntentInfo"
          },
          "type": "array",
          "description": "Read-only. Information about all followup intents that have this intent as a direct or indirect parent. We populate this field only in the output."
        },
        "resetContexts": {
          "type": "boolean",
          "description": "Optional. Indicates whether to delete all contexts in the current session when this intent is matched."
        }
      },
      "description": "An intent categorizes an end-user's intention for one conversation turn. For each agent, you define many intents, where your combined intents can handle a complete conversation. When an end-user writes or says something, referred to as an end-user expression or end-user input, Dialogflow matches the end-user input to the best intent in your agent. Matching an intent is also known as intent classification. For more information, see the [intent guide](https://cloud.google.com/dialogflow/docs/intents-overview).",
      "type": "object"
    },
    "GoogleCloudDialogflowV2BatchUpdateIntentsResponse": {
      "description": "The response message for Intents.BatchUpdateIntents.",
      "type": "object",
      "id": "GoogleCloudDialogflowV2BatchUpdateIntentsResponse",
      "properties": {
        "intents": {
          "description": "The collection of updated or created intents.",
          "type": "array",
          "items": {
            "$ref": "GoogleCloudDialogflowV2Intent"
          }
        }
      }
    },
    "GoogleCloudDialogflowV2beta1IntentMessageText": {
      "description": "The text response message.",
      "type": "object",
      "id": "GoogleCloudDialogflowV2beta1IntentMessageText",
      "properties": {
        "text": {
          "description": "Optional. The collection of the agent's responses.",
          "type": "array",
          "items": {
            "type": "string"
          }
        }
      }
    },
    "GoogleCloudDialogflowV2beta1IntentFollowupIntentInfo": {
      "properties": {
        "followupIntentName": {
          "type": "string",
          "description": "The unique identifier of the followup intent. Format: `projects//agent/intents/`."
        },
        "parentFollowupIntentName": {
          "type": "string",
          "description": "The unique identifier of the followup intent's parent. Format: `projects//agent/intents/`."
        }
      },
      "id": "GoogleCloudDialogflowV2beta1IntentFollowupIntentInfo",
      "type": "object",
      "description": "Represents a single followup intent in the chain."
    },
    "GoogleCloudDialogflowV2IntentMessageBasicCard": {
      "description": "The basic card message. Useful for displaying information.",
      "id": "GoogleCloudDialogflowV2IntentMessageBasicCard",
      "type": "object",
      "properties": {
        "title": {
          "description": "Optional. The title of the card.",
          "type": "string"
        },
        "image": {
          "$ref": "GoogleCloudDialogflowV2IntentMessageImage",
          "description": "Optional. The image for the card."
        },
        "formattedText": {
          "type": "string",
          "description": "Required, unless image is present. The body text of the card."
        },
        "subtitle": {
          "type": "string",
          "description": "Optional. The subtitle of the card."
        },
        "buttons": {
          "type": "array",
          "description": "Optional. The collection of card buttons.",
          "items": {
            "$ref": "GoogleCloudDialogflowV2IntentMessageBasicCardButton"
          }
        }
      }
    },
    "GoogleCloudDialogflowV2IntentMessageCarouselSelect": {
      "properties": {
        "items": {
          "description": "Required. Carousel items.",
          "items": {
            "$ref": "GoogleCloudDialogflowV2IntentMessageCarouselSelectItem"
          },
          "type": "array"
        }
      },
      "type": "object",
      "description": "The card for presenting a carousel of options to select from.",
      "id": "GoogleCloudDialogflowV2IntentMessageCarouselSelect"
    },
    "GoogleCloudDialogflowV2beta1WebhookRequest": {
      "type": "object",
      "description": "The request message for a webhook call.",
      "id": "GoogleCloudDialogflowV2beta1WebhookRequest",
      "properties": {
        "alternativeQueryResults": {
          "type": "array",
          "description": "Alternative query results from KnowledgeService.",
          "items": {
            "$ref": "GoogleCloudDialogflowV2beta1QueryResult"
          }
        },
        "session": {
          "description": "The unique identifier of detectIntent request session. Can be used to identify end-user inside webhook implementation. Format: `projects//agent/sessions/`, or `projects//agent/environments//users//sessions/`.",
          "type": "string"
        },
        "responseId": {
          "description": "The unique identifier of the response. Contains the same value as `[Streaming]DetectIntentResponse.response_id`.",
          "type": "string"
        },
        "queryResult": {
          "$ref": "GoogleCloudDialogflowV2beta1QueryResult",
          "description": "The result of the conversational query or event processing. Contains the same value as `[Streaming]DetectIntentResponse.query_result`."
        },
        "originalDetectIntentRequest": {
          "$ref": "GoogleCloudDialogflowV2beta1OriginalDetectIntentRequest",
          "description": "Optional. The contents of the original request that was passed to `[Streaming]DetectIntent` call."
        }
      }
    },
    "GoogleCloudDialogflowV2beta1IntentMessageCarouselSelectItem": {
      "description": "An item in the carousel.",
      "id": "GoogleCloudDialogflowV2beta1IntentMessageCarouselSelectItem",
      "properties": {
        "info": {
          "$ref": "GoogleCloudDialogflowV2beta1IntentMessageSelectItemInfo",
          "description": "Required. Additional info about the option item."
        },
        "title": {
          "description": "Required. Title of the carousel item.",
          "type": "string"
        },
        "image": {
          "description": "Optional. The image to display.",
          "$ref": "GoogleCloudDialogflowV2beta1IntentMessageImage"
        },
        "description": {
          "type": "string",
          "description": "Optional. The body text of the card."
        }
      },
      "type": "object"
    },
    "GoogleCloudDialogflowV2IntentMessageCarouselSelectItem": {
      "id": "GoogleCloudDialogflowV2IntentMessageCarouselSelectItem",
      "properties": {
        "image": {
          "$ref": "GoogleCloudDialogflowV2IntentMessageImage",
          "description": "Optional. The image to display."
        },
        "title": {
          "description": "Required. Title of the carousel item.",
          "type": "string"
        },
        "description": {
          "description": "Optional. The body text of the card.",
          "type": "string"
        },
        "info": {
          "$ref": "GoogleCloudDialogflowV2IntentMessageSelectItemInfo",
          "description": "Required. Additional info about the option item."
        }
      },
      "type": "object",
      "description": "An item in the carousel."
    }
  },
  "name": "dialogflow",
  "parameters": {
    "oauth_token": {
      "type": "string",
      "description": "OAuth 2.0 token for the current user.",
      "location": "query"
    },
    "key": {
      "type": "string",
      "location": "query",
      "description": "API key. Your API key identifies your project and provides you with API access, quota, and reports. Required unless you provide an OAuth 2.0 token."
    },
    "uploadType": {
      "type": "string",
      "location": "query",
      "description": "Legacy upload protocol for media (e.g. \"media\", \"multipart\")."
    },
    "$.xgafv": {
      "enumDescriptions": [
        "v1 error format",
        "v2 error format"
      ],
      "description": "V1 error format.",
      "enum": [
        "1",
        "2"
      ],
      "location": "query",
      "type": "string"
    },
    "alt": {
      "enumDescriptions": [
        "Responses with Content-Type of application/json",
        "Media download with context-dependent Content-Type",
        "Responses with Content-Type of application/x-protobuf"
      ],
      "description": "Data format for response.",
      "default": "json",
      "location": "query",
      "type": "string",
      "enum": [
        "json",
        "media",
        "proto"
      ]
    },
    "prettyPrint": {
      "description": "Returns response with indentations and line breaks.",
      "type": "boolean",
      "location": "query",
      "default": "true"
    },
    "fields": {
      "description": "Selector specifying which fields to include in a partial response.",
      "location": "query",
      "type": "string"
    },
    "access_token": {
      "description": "OAuth access token.",
      "type": "string",
      "location": "query"
    },
    "quotaUser": {
      "type": "string",
      "location": "query",
      "description": "Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters."
    },
    "callback": {
      "description": "JSONP",
      "location": "query",
      "type": "string"
    },
    "upload_protocol": {
      "location": "query",
      "type": "string",
      "description": "Upload protocol for media (e.g. \"raw\", \"multipart\")."
    }
  },
  "title": "Dialogflow API",
  "discoveryVersion": "v1",
  "documentationLink": "https://cloud.google.com/dialogflow/",
  "version": "v3beta1",
  "basePath": "",
  "rootUrl": "https://dialogflow.googleapis.com/",
  "revision": "20200810",
  "resources": {
    "projects": {
      "resources": {
        "locations": {
          "resources": {
            "operations": {
              "methods": {
                "cancel": {
                  "httpMethod": "POST",
                  "parameters": {
                    "name": {
                      "type": "string",
                      "location": "path",
                      "required": true,
                      "pattern": "^projects/[^/]+/locations/[^/]+/operations/[^/]+$",
                      "description": "The name of the operation resource to be cancelled."
                    }
                  },
                  "parameterOrder": [
                    "name"
                  ],
                  "path": "v3beta1/{+name}:cancel",
                  "response": {
                    "$ref": "GoogleProtobufEmpty"
                  },
                  "description": "Starts asynchronous cancellation on a long-running operation. The server makes a best effort to cancel the operation, but success is not guaranteed. If the server doesn't support this method, it returns `google.rpc.Code.UNIMPLEMENTED`. Clients can use Operations.GetOperation or other methods to check whether the cancellation succeeded or whether the operation completed despite cancellation. On successful cancellation, the operation is not deleted; instead, it becomes an operation with an Operation.error value with a google.rpc.Status.code of 1, corresponding to `Code.CANCELLED`.",
                  "id": "dialogflow.projects.locations.operations.cancel",
                  "flatPath": "v3beta1/projects/{projectsId}/locations/{locationsId}/operations/{operationsId}:cancel",
                  "scopes": [
                    "https://www.googleapis.com/auth/cloud-platform",
                    "https://www.googleapis.com/auth/dialogflow"
                  ]
                },
                "get": {
                  "response": {
                    "$ref": "GoogleLongrunningOperation"
                  },
                  "id": "dialogflow.projects.locations.operations.get",
                  "description": "Gets the latest state of a long-running operation. Clients can use this method to poll the operation result at intervals as recommended by the API service.",
                  "httpMethod": "GET",
                  "parameterOrder": [
                    "name"
                  ],
                  "flatPath": "v3beta1/projects/{projectsId}/locations/{locationsId}/operations/{operationsId}",
                  "parameters": {
                    "name": {
                      "location": "path",
                      "type": "string",
                      "description": "The name of the operation resource.",
                      "pattern": "^projects/[^/]+/locations/[^/]+/operations/[^/]+$",
                      "required": true
                    }
                  },
                  "scopes": [
                    "https://www.googleapis.com/auth/cloud-platform",
                    "https://www.googleapis.com/auth/dialogflow"
                  ],
                  "path": "v3beta1/{+name}"
                },
                "list": {
                  "description": "Lists operations that match the specified filter in the request. If the server doesn't support this method, it returns `UNIMPLEMENTED`. NOTE: the `name` binding allows API services to override the binding to use different resource name schemes, such as `users/*/operations`. To override the binding, API services can add a binding such as `\"/v1/{name=users/*}/operations\"` to their service configuration. For backwards compatibility, the default name includes the operations collection id, however overriding users must ensure the name binding is the parent resource, without the operations collection id.",
                  "path": "v3beta1/{+name}/operations",
                  "flatPath": "v3beta1/projects/{projectsId}/locations/{locationsId}/operations",
                  "parameters": {
                    "pageToken": {
                      "location": "query",
                      "type": "string",
                      "description": "The standard list page token."
                    },
                    "pageSize": {
                      "location": "query",
                      "format": "int32",
                      "description": "The standard list page size.",
                      "type": "integer"
                    },
                    "filter": {
                      "location": "query",
                      "type": "string",
                      "description": "The standard list filter."
                    },
                    "name": {
                      "required": true,
                      "pattern": "^projects/[^/]+/locations/[^/]+$",
                      "description": "The name of the operation's parent resource.",
                      "type": "string",
                      "location": "path"
                    }
                  },
                  "response": {
                    "$ref": "GoogleLongrunningListOperationsResponse"
                  },
                  "scopes": [
                    "https://www.googleapis.com/auth/cloud-platform",
                    "https://www.googleapis.com/auth/dialogflow"
                  ],
                  "id": "dialogflow.projects.locations.operations.list",
                  "httpMethod": "GET",
                  "parameterOrder": [
                    "name"
                  ]
                }
              }
            }
          }
        },
        "operations": {
          "methods": {
            "list": {
              "response": {
                "$ref": "GoogleLongrunningListOperationsResponse"
              },
              "scopes": [
                "https://www.googleapis.com/auth/cloud-platform",
                "https://www.googleapis.com/auth/dialogflow"
              ],
              "flatPath": "v3beta1/projects/{projectsId}/operations",
              "id": "dialogflow.projects.operations.list",
              "parameterOrder": [
                "name"
              ],
              "description": "Lists operations that match the specified filter in the request. If the server doesn't support this method, it returns `UNIMPLEMENTED`. NOTE: the `name` binding allows API services to override the binding to use different resource name schemes, such as `users/*/operations`. To override the binding, API services can add a binding such as `\"/v1/{name=users/*}/operations\"` to their service configuration. For backwards compatibility, the default name includes the operations collection id, however overriding users must ensure the name binding is the parent resource, without the operations collection id.",
              "httpMethod": "GET",
              "path": "v3beta1/{+name}/operations",
              "parameters": {
                "filter": {
                  "description": "The standard list filter.",
                  "location": "query",
                  "type": "string"
                },
                "pageToken": {
                  "type": "string",
                  "location": "query",
                  "description": "The standard list page token."
                },
                "pageSize": {
                  "location": "query",
                  "format": "int32",
                  "type": "integer",
                  "description": "The standard list page size."
                },
                "name": {
                  "location": "path",
                  "description": "The name of the operation's parent resource.",
                  "required": true,
                  "pattern": "^projects/[^/]+$",
                  "type": "string"
                }
              }
            },
            "cancel": {
              "parameterOrder": [
                "name"
              ],
              "id": "dialogflow.projects.operations.cancel",
              "parameters": {
                "name": {
                  "pattern": "^projects/[^/]+/operations/[^/]+$",
                  "type": "string",
                  "description": "The name of the operation resource to be cancelled.",
                  "location": "path",
                  "required": true
                }
              },
              "response": {
                "$ref": "GoogleProtobufEmpty"
              },
              "description": "Starts asynchronous cancellation on a long-running operation. The server makes a best effort to cancel the operation, but success is not guaranteed. If the server doesn't support this method, it returns `google.rpc.Code.UNIMPLEMENTED`. Clients can use Operations.GetOperation or other methods to check whether the cancellation succeeded or whether the operation completed despite cancellation. On successful cancellation, the operation is not deleted; instead, it becomes an operation with an Operation.error value with a google.rpc.Status.code of 1, corresponding to `Code.CANCELLED`.",
              "scopes": [
                "https://www.googleapis.com/auth/cloud-platform",
                "https://www.googleapis.com/auth/dialogflow"
              ],
              "flatPath": "v3beta1/projects/{projectsId}/operations/{operationsId}:cancel",
              "path": "v3beta1/{+name}:cancel",
              "httpMethod": "POST"
            },
            "get": {
              "parameters": {
                "name": {
                  "location": "path",
                  "type": "string",
                  "required": true,
                  "description": "The name of the operation resource.",
                  "pattern": "^projects/[^/]+/operations/[^/]+$"
                }
              },
              "id": "dialogflow.projects.operations.get",
              "description": "Gets the latest state of a long-running operation. Clients can use this method to poll the operation result at intervals as recommended by the API service.",
              "parameterOrder": [
                "name"
              ],
              "httpMethod": "GET",
              "path": "v3beta1/{+name}",
              "response": {
                "$ref": "GoogleLongrunningOperation"
              },
              "flatPath": "v3beta1/projects/{projectsId}/operations/{operationsId}",
              "scopes": [
                "https://www.googleapis.com/auth/cloud-platform",
                "https://www.googleapis.com/auth/dialogflow"
              ]
            }
          }
        }
      }
    }
  },
  "ownerDomain": "google.com",
  "mtlsRootUrl": "https://dialogflow.mtls.googleapis.com/",
  "icons": {
    "x32": "http://www.google.com/images/icons/product/search-32.gif",
    "x16": "http://www.google.com/images/icons/product/search-16.gif"
  },
  "auth": {
    "oauth2": {
      "scopes": {
        "https://www.googleapis.com/auth/cloud-platform": {
          "description": "View and manage your data across Google Cloud Platform services"
        },
        "https://www.googleapis.com/auth/dialogflow": {
          "description": "View, manage and query your Dialogflow agents"
        }
      }
    }
  }
}
